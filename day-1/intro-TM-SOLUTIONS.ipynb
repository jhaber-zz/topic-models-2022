{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Topic Modeling\n",
    "## Day 1: The Basics&mdash;SOLUTIONS\n",
    "---\n",
    "---\n",
    "\n",
    "\n",
    "## Outline\n",
    "- [The Pandas dataframe: Children's literature](#data)\n",
    "- [Text preprocessing: The Document-Term Matrix (DTM)](#preprocess)\n",
    "- [Train a topic model using LDA](#train)\n",
    "- [Document-by-topic distribution](#topics)\n",
    "- [LDA as dimensionality reduction](#dimensionality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pandas dataframe: Children's literature <a id='data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author gender</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Dog with a Bad Name</td>\n",
       "      <td>Male</td>\n",
       "      <td>1886</td>\n",
       "      <td>A DOG WITH A BAD NAME  BY TALBOT BAINES REED  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Final Reckoning</td>\n",
       "      <td>Male</td>\n",
       "      <td>1887</td>\n",
       "      <td>A Final Reckoning: A Tale of Bush Life in Aust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A House Party, Don Gesualdo, and A Rainy June</td>\n",
       "      <td>Female</td>\n",
       "      <td>1887</td>\n",
       "      <td>A HOUSE-PARTY  Don Gesualdo  and  A Rainy June...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Houseful of Girls</td>\n",
       "      <td>Female</td>\n",
       "      <td>1889</td>\n",
       "      <td>A HOUSEFUL OF GIRLS. BY SARAH TYTLER,  AUTHOR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Little Country Girl</td>\n",
       "      <td>Female</td>\n",
       "      <td>1885</td>\n",
       "      <td>LITTLE COUNTRY GIRL.  BY  SUSAN COOLIDGE,     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Up the River</td>\n",
       "      <td>Male</td>\n",
       "      <td>1881</td>\n",
       "      <td>UP THE RIVER  OR  YACHTING ON THE MISSISSIPPI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>What Katy Did Next</td>\n",
       "      <td>Female</td>\n",
       "      <td>1886</td>\n",
       "      <td>WHAT KATY DID NEXT  BY  SUSAN COOLIDGE    This...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Winning His Spurs</td>\n",
       "      <td>Male</td>\n",
       "      <td>1882</td>\n",
       "      <td>WINNING HIS SPURS            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>With Clive in India</td>\n",
       "      <td>Male</td>\n",
       "      <td>1884</td>\n",
       "      <td>WITH CLIVE IN INDIA:  Or, The Beginnings of an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>With Wolfe in Canada</td>\n",
       "      <td>Male</td>\n",
       "      <td>1887</td>\n",
       "      <td>\\n WITH WOLFE IN CANADA  Or The Winning of a C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title author gender  year  \\\n",
       "0                            A Dog with a Bad Name          Male  1886   \n",
       "1                                A Final Reckoning          Male  1887   \n",
       "2    A House Party, Don Gesualdo, and A Rainy June        Female  1887   \n",
       "3                              A Houseful of Girls        Female  1889   \n",
       "4                            A Little Country Girl        Female  1885   \n",
       "..                                             ...           ...   ...   \n",
       "127                                   Up the River          Male  1881   \n",
       "128                             What Katy Did Next        Female  1886   \n",
       "129                              Winning His Spurs          Male  1882   \n",
       "130                            With Clive in India          Male  1884   \n",
       "131                           With Wolfe in Canada          Male  1887   \n",
       "\n",
       "                                                  text  \n",
       "0    A DOG WITH A BAD NAME  BY TALBOT BAINES REED  ...  \n",
       "1    A Final Reckoning: A Tale of Bush Life in Aust...  \n",
       "2    A HOUSE-PARTY  Don Gesualdo  and  A Rainy June...  \n",
       "3    A HOUSEFUL OF GIRLS. BY SARAH TYTLER,  AUTHOR ...  \n",
       "4    LITTLE COUNTRY GIRL.  BY  SUSAN COOLIDGE,     ...  \n",
       "..                                                 ...  \n",
       "127  UP THE RIVER  OR  YACHTING ON THE MISSISSIPPI ...  \n",
       "128  WHAT KATY DID NEXT  BY  SUSAN COOLIDGE    This...  \n",
       "129                   WINNING HIS SPURS            ...  \n",
       "130  WITH CLIVE IN INDIA:  Or, The Beginnings of an...  \n",
       "131  \\n WITH WOLFE IN CANADA  Or The Winning of a C...  \n",
       "\n",
       "[127 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_lit = pd.read_csv(\"../assets/childrens_lit.csv.bz2\", \n",
    "                     sep='\\t', \n",
    "                     index_col=0, \n",
    "                     encoding = 'utf-8', \n",
    "                     compression='bz2')\n",
    "\n",
    "#drop rows where the text is missing.\n",
    "df_lit = df_lit.dropna(subset=['text'])\n",
    "\n",
    "#view the dataframe\n",
    "df_lit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing: The Document-Term Matrix (DTM) <a id='preprocess'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Vectorize our text using CountVectorizer\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.80, min_df=50,\n",
    "                                max_features=None,\n",
    "                                stop_words='english')\n",
    "\n",
    "dtm = tf_vectorizer.fit_transform(df_lit.text)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "* Print out the 10 most _infrequent_ words (rather than the most frequent words). You can look at the [Pandas documentation](http://pandas.pydata.org/pandas-docs/stable/api.html#api-dataframe-stats) for more information.\n",
    "* Print the average number of times 10 most frequent and the 10 most infrequent words are used in a book.\n",
    "* Print this out sorted from highest to lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alteration    54\n",
       "production    61\n",
       "include       61\n",
       "contract      63\n",
       "calculate     64\n",
       "sharing       68\n",
       "assisting     68\n",
       "cling         69\n",
       "oblige        71\n",
       "indicating    71\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solution 1\n",
    "vocab = tf_vectorizer.get_feature_names_out() # save terms in vectorizer for later use \n",
    "\n",
    "# Convert sparse to long-format DTM (not memory-efficient)\n",
    "long_dtm = pd.DataFrame(dtm.toarray(), \n",
    "                        columns=vocab, \n",
    "                        index=df_lit.index)\n",
    "\n",
    "# Print least frequent words\n",
    "long_dtm.sum().sort_values().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doctor     39.622047\n",
      "dick       38.244094\n",
      "king       35.354331\n",
      "jack       29.818898\n",
      "uncle      28.976378\n",
      "tom        25.188976\n",
      "ship       21.748031\n",
      "project    21.559055\n",
      "army       21.535433\n",
      "french     21.078740\n",
      "dtype: float64\n",
      "\n",
      "alteration    0.425197\n",
      "production    0.480315\n",
      "include       0.480315\n",
      "contract      0.496063\n",
      "calculate     0.503937\n",
      "sharing       0.535433\n",
      "assisting     0.535433\n",
      "cling         0.543307\n",
      "oblige        0.559055\n",
      "indicating    0.559055\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# solution 2\n",
    "print(long_dtm.mean().sort_values(ascending=False).head(10))\n",
    "print()\n",
    "print(long_dtm.mean().sort_values(ascending=True).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doctor     39.622047\n",
      "dick       38.244094\n",
      "king       35.354331\n",
      "jack       29.818898\n",
      "uncle      28.976378\n",
      "tom        25.188976\n",
      "ship       21.748031\n",
      "project    21.559055\n",
      "army       21.535433\n",
      "french     21.078740\n",
      "dtype: float64\n",
      "\n",
      "indicating    0.559055\n",
      "oblige        0.559055\n",
      "cling         0.543307\n",
      "assisting     0.535433\n",
      "sharing       0.535433\n",
      "calculate     0.503937\n",
      "contract      0.496063\n",
      "include       0.480315\n",
      "production    0.480315\n",
      "alteration    0.425197\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# solution 3\n",
    "print(long_dtm.mean().sort_values(ascending=False).head(10))\n",
    "print()\n",
    "print(long_dtm.mean().sort_values(ascending=True).head(10).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra challenge\n",
    "\n",
    "What are the most frequent words for male and female authors?\n",
    "\n",
    "_Hints:_ First, join the long-format DTM with the main DataFrame (`pd.concat(axis=1)` works well for this). Then filter by gender. Once this is done, remove the columns from the original DF before you print frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author gender</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "      <th>30</th>\n",
       "      <th>50</th>\n",
       "      <th>_you_</th>\n",
       "      <th>...</th>\n",
       "      <th>yelling</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yells</th>\n",
       "      <th>yer</th>\n",
       "      <th>yield</th>\n",
       "      <th>yielded</th>\n",
       "      <th>yonder</th>\n",
       "      <th>york</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Dog with a Bad Name</td>\n",
       "      <td>Male</td>\n",
       "      <td>1886</td>\n",
       "      <td>A DOG WITH A BAD NAME  BY TALBOT BAINES REED  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Final Reckoning</td>\n",
       "      <td>Male</td>\n",
       "      <td>1887</td>\n",
       "      <td>A Final Reckoning: A Tale of Bush Life in Aust...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A House Party, Don Gesualdo, and A Rainy June</td>\n",
       "      <td>Female</td>\n",
       "      <td>1887</td>\n",
       "      <td>A HOUSE-PARTY  Don Gesualdo  and  A Rainy June...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Houseful of Girls</td>\n",
       "      <td>Female</td>\n",
       "      <td>1889</td>\n",
       "      <td>A HOUSEFUL OF GIRLS. BY SARAH TYTLER,  AUTHOR ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Little Country Girl</td>\n",
       "      <td>Female</td>\n",
       "      <td>1885</td>\n",
       "      <td>LITTLE COUNTRY GIRL.  BY  SUSAN COOLIDGE,     ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title author gender  year  \\\n",
       "0                          A Dog with a Bad Name          Male  1886   \n",
       "1                              A Final Reckoning          Male  1887   \n",
       "2  A House Party, Don Gesualdo, and A Rainy June        Female  1887   \n",
       "3                            A Houseful of Girls        Female  1889   \n",
       "4                          A Little Country Girl        Female  1885   \n",
       "\n",
       "                                                text  000  10  20  30  50  \\\n",
       "0  A DOG WITH A BAD NAME  BY TALBOT BAINES REED  ...    0   1   0   1   0   \n",
       "1  A Final Reckoning: A Tale of Bush Life in Aust...    0   2   4   1   1   \n",
       "2  A HOUSE-PARTY  Don Gesualdo  and  A Rainy June...    0   1   0   0   0   \n",
       "3  A HOUSEFUL OF GIRLS. BY SARAH TYTLER,  AUTHOR ...    0   0   1   0   0   \n",
       "4  LITTLE COUNTRY GIRL.  BY  SUSAN COOLIDGE,     ...    0   0   0   0   0   \n",
       "\n",
       "   _you_  ...  yelling  yellow  yells  yer  yield  yielded  yonder  york  \\\n",
       "0      7  ...        1       1      2    0      0        5       1    23   \n",
       "1      0  ...        1       0      2    2      0        0       0     0   \n",
       "2      2  ...        0       6      0    0      0        2       3     0   \n",
       "3      3  ...        1       2      0    0      1        4       0     0   \n",
       "4      0  ...        0      16      0    0      1        0       1     4   \n",
       "\n",
       "   youngest  youth  \n",
       "0         1     14  \n",
       "1         0      2  \n",
       "2         1     13  \n",
       "3         7     13  \n",
       "4         3      1  \n",
       "\n",
       "[5 rows x 3201 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solution\n",
    "# First, let's join the long-format DTM with the main DataFrame\n",
    "df_w_dtm = pd.concat([df_lit, long_dtm.fillna(0)], axis=1)\n",
    "df_w_dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author gender</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "      <th>30</th>\n",
       "      <th>50</th>\n",
       "      <th>_you_</th>\n",
       "      <th>...</th>\n",
       "      <th>yelling</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yells</th>\n",
       "      <th>yer</th>\n",
       "      <th>yield</th>\n",
       "      <th>yielded</th>\n",
       "      <th>yonder</th>\n",
       "      <th>york</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Dog with a Bad Name</td>\n",
       "      <td>Male</td>\n",
       "      <td>1886</td>\n",
       "      <td>A DOG WITH A BAD NAME  BY TALBOT BAINES REED  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Final Reckoning</td>\n",
       "      <td>Male</td>\n",
       "      <td>1887</td>\n",
       "      <td>A Final Reckoning: A Tale of Bush Life in Aust...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adrift in the Wild</td>\n",
       "      <td>Male</td>\n",
       "      <td>1887</td>\n",
       "      <td>Adrift in the Wilds;          ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Adventures in Africa</td>\n",
       "      <td>Male</td>\n",
       "      <td>1883</td>\n",
       "      <td>ADVENTURES IN AFRICA, BY W.H.G. KINGSTON.    C...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Adventures in Australia</td>\n",
       "      <td>Male</td>\n",
       "      <td>1885</td>\n",
       "      <td>ADVENTURES IN AUSTRALIA, BY W.H.G. KINGSTON.  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title author gender  year  \\\n",
       "0     A Dog with a Bad Name          Male  1886   \n",
       "1         A Final Reckoning          Male  1887   \n",
       "8        Adrift in the Wild          Male  1887   \n",
       "9      Adventures in Africa          Male  1883   \n",
       "10  Adventures in Australia          Male  1885   \n",
       "\n",
       "                                                 text  000  10  20  30  50  \\\n",
       "0   A DOG WITH A BAD NAME  BY TALBOT BAINES REED  ...    0   1   0   1   0   \n",
       "1   A Final Reckoning: A Tale of Bush Life in Aust...    0   2   4   1   1   \n",
       "8                   Adrift in the Wilds;          ...    1   0   0   0   0   \n",
       "9   ADVENTURES IN AFRICA, BY W.H.G. KINGSTON.    C...    0   0   0   0   0   \n",
       "10  ADVENTURES IN AUSTRALIA, BY W.H.G. KINGSTON.  ...    0   0   0   0   0   \n",
       "\n",
       "    _you_  ...  yelling  yellow  yells  yer  yield  yielded  yonder  york  \\\n",
       "0       7  ...        1       1      2    0      0        5       1    23   \n",
       "1       0  ...        1       0      2    2      0        0       0     0   \n",
       "8       2  ...        0       3      0    6      2        0       8     7   \n",
       "9       0  ...        0       4      1    0      0        0       2     0   \n",
       "10      0  ...        1       1      1    0      4        0       1     0   \n",
       "\n",
       "    youngest  youth  \n",
       "0          1     14  \n",
       "1          0      2  \n",
       "8          0      0  \n",
       "9          0      1  \n",
       "10         1      1  \n",
       "\n",
       "[5 rows x 3201 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then let's filter into separate DFs by author gender\n",
    "male_author_dtm = df_w_dtm[df_w_dtm[\"author gender\"]==\"Male\"]\n",
    "female_author_dtm = df_w_dtm[df_w_dtm[\"author gender\"]==\"Female\"]\n",
    "\n",
    "male_author_dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py:4167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "      <th>30</th>\n",
       "      <th>50</th>\n",
       "      <th>_you_</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>ability</th>\n",
       "      <th>abode</th>\n",
       "      <th>abreast</th>\n",
       "      <th>...</th>\n",
       "      <th>yelling</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yells</th>\n",
       "      <th>yer</th>\n",
       "      <th>yield</th>\n",
       "      <th>yielded</th>\n",
       "      <th>yonder</th>\n",
       "      <th>york</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    000  10  20  30  50  _you_  abandoned  ability  abode  abreast  ...  \\\n",
       "0     0   1   0   1   0      7          0        0      1        0  ...   \n",
       "1     0   2   4   1   1      0          2        1      2        2  ...   \n",
       "8     1   0   0   0   0      2          1        2      0        0  ...   \n",
       "9     0   0   0   0   0      0          1        0      0        1  ...   \n",
       "10    0   0   0   0   0      0          0        0      1        0  ...   \n",
       "\n",
       "    yelling  yellow  yells  yer  yield  yielded  yonder  york  youngest  youth  \n",
       "0         1       1      2    0      0        5       1    23         1     14  \n",
       "1         1       0      2    2      0        0       0     0         0      2  \n",
       "8         0       3      0    6      2        0       8     7         0      0  \n",
       "9         0       4      1    0      0        0       2     0         0      1  \n",
       "10        1       1      1    0      4        0       1     0         1      1  \n",
       "\n",
       "[5 rows x 3196 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's remove the columns from the original DF so we can sort just by word columns from DTM\n",
    "male_author_dtm.drop(columns = df_lit.columns, inplace = True)\n",
    "female_author_dtm.drop(columns = df_lit.columns, inplace = True)\n",
    "\n",
    "male_author_dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent words by male authors:\n",
      "dick      4562\n",
      "doctor    4415\n",
      "king      4333\n",
      "jack      3708\n",
      "uncle     3284\n",
      "army      2699\n",
      "ship      2673\n",
      "tom       2648\n",
      "camp      2622\n",
      "french    2445\n",
      "dtype: int64\n",
      "\n",
      "Most frequent words by female authors:\n",
      "girls     1319\n",
      "mamma      985\n",
      "papa       973\n",
      "aunt       711\n",
      "sister     686\n",
      "baby       680\n",
      "doctor     617\n",
      "sweet      584\n",
      "tom        551\n",
      "flower     501\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# finally, let's look at top words for each of these gender-specific DFs\n",
    "print(\"Most frequent words by male authors:\")\n",
    "print(male_author_dtm.sum().sort_values(ascending=False).head(10))\n",
    "print()\n",
    "print(\"Most frequent words by female authors:\")\n",
    "print(female_author_dtm.sum().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a topic model using LDA <a id='train'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **❗Important Note: Topic models are not perfectly reproducible, so you may see different topics, words, and/or probabilities  from what others see. This means my examples may not match up exactly with what you see when you run the notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "n_samples = 2000\n",
    "n_topics = 4\n",
    "n_top_words = 50\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Copy and paste the above code and fit a new model, `lda_new`, by changing some of the parameters. How does this change the output?\n",
    "\n",
    "Suggestions:\n",
    "1. Change the number of topics. \n",
    "2. Do not remove stop words. \n",
    "3. Change other options, either in the vectorize stage or the LDA model.\n",
    "\n",
    "_Hint:_ If you change the text vectorization method, don't forget to re-define your vocabulary for the `print_top_words()` function with code like this:\n",
    "```python\n",
    "vocab = tf_vectorizer.get_feature_names_out()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LDA model with tf features, n_samples=2000 and n_topics=10...\n",
      "Done!\n",
      "\n",
      "Topics in LDA model:\n",
      "\n",
      "Topic #0:\n",
      "project doctor girls papa sister mamma baby london street tom sweet dr tea aunt works remarked ain em foundation study office wasn cousin youth ladies presently darling flower public everybody loved george shop nurse ye ma class uncle stairs bell reader st regard doesn carriage agreement observed flowers demanded sisters\n",
      "\n",
      "Topic #1:\n",
      "dick uncle tom doctor fish jack em rope lads rock ay shock birds gun mate fishing beneath garden sand stream nay moments rocks eh excitedly thrust hook yer tremendous ashore ha pole ye softly fruit shore angrily growled ship gazing surface chap leg works deck ladder basket splash tail task\n",
      "\n",
      "Topic #2:\n",
      "king army french troops attack ship officers camp soldiers officer shore village city guns john boats regiment deck march tom vessel fort prince british rode advanced wounded james island native marched fleet ships france lads prisoners numbers band speed lake sword sail column castle fought jack south forest considerable coast\n",
      "\n",
      "Topic #3:\n",
      "project ma doctor church works james regiment soldier girls tent foundation cheese camp minister rode soldiers female anybody officers army officer states store stairs college public boots teacher woods agreement kicked ride sunday tail shirt bottle guess united corn office street copy society saddle fence stomach bridge heaven angel leg\n",
      "\n",
      "Topic #4:\n",
      "king jack frank uncle troops french john ship camp attack army city village shore soldiers doctor prince dick james deck boats arrows tom street forest coast march officer em ye lake band ain wounded fish native project guns advanced london officers stream lads fired ha rope rock works presently numbers\n",
      "\n",
      "Topic #5:\n",
      "ye uncle ay king ship rock james sword folk scarce deck soldiers shore bottle presently south island cries george hills crying anger murder rocks mountains farther french valley seas france brandy sore doctor seek john coats plainly shame doubtless mountain gentlemen aloud desert bush ashore pistol meat kitchen east officer\n",
      "\n",
      "Topic #6:\n",
      "er ain den uncle yer wolf jack folks lion gun dish tail sing jump aunt seed study doctor goodness bag meat fish john bird win fix eve rock ha nigh fool woods fur song butter somebody baby deer outer bull patch christmas tie ho chap responded bushes fuss pot inquired\n",
      "\n",
      "Topic #7:\n",
      "frank ain dick uncle camp john em pounds bush stream doctor attack innocent mate dr nigh den village coast rode shore boats hunters cousin meat guilty fort ship illustration tea chap presently tent claim wasn cases reckon street cabin officer king evidence ride station afore fever public warn valley steady\n",
      "\n",
      "Topic #8:\n",
      "jack king prince palace queen thou castle majesty city cat court presently giant beauty beast ha john marry ring maid street lads charming brothers garden mountain royal golden girls crown sword dogs kingdom tail married thee ship village st wine youth boots bull forest em loved sister office servants chamber\n",
      "\n",
      "Topic #9:\n",
      "doctor camp indian john ha arrows rock em mountain rode ship penny maiden ride rocks sword pine savage band bushes mountains gun wounded lake attack stream jack yellow enemies knife cattle mistress pony deer ye prisoner island hunting shore mounted heaven valley warning bears forest king farther stones meat animal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# solution 1\n",
    "\n",
    "n_samples = 2000\n",
    "n_topics = 10\n",
    "n_top_words = 50\n",
    "\n",
    "print(\"Fitting LDA model with tf features, \"\n",
    "      \"n_samples=%d and n_topics=%d...\"\n",
    "      % (n_samples, n_topics))\n",
    "\n",
    "#define the lda function, with desired options\n",
    "#Check the documentation, linked above, to look through the options\n",
    "lda_new = LDA(n_components=n_topics, \n",
    "          max_iter=20,\n",
    "          learning_method='online',\n",
    "          learning_offset=80.,\n",
    "          total_samples=n_samples,\n",
    "          random_state=0)\n",
    "\n",
    "#fit the model\n",
    "lda_new.fit(dtm)\n",
    "print(\"Done!\")\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "print_top_words(lda_new, vocab, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "Done!\n",
      "Fitting LDA model with tf features, n_samples=2000 and n_topics=10...\n",
      "Done!\n",
      "\n",
      "Topics in LDA model:\n",
      "\n",
      "Topic #0:\n",
      "dick uncle tom doctor fish jack em lads rope rock towards ay birds rocks gun beneath nay excitedly fishing stream moments thrust eh sand hook shock tremendous ha mate softly growled ashore stones angrily farther ship toward surface shore task leg works gazing horrible garden pole bird roar ye tail\n",
      "\n",
      "Topic #1:\n",
      "frank ain uncle dick em camp john tom pounds stream ship coast doctor dr project attack ye shore innocent mate nigh tent hunters street boats tea claim village cases cousin fort illustration wasn meat chap reckon rode towards public cabin king officer guilty london fever lads ice considerable afore de\n",
      "\n",
      "Topic #2:\n",
      "king john army city prince ship attack troops castle soldiers france french sword towards camp ships shore fought numbers prisoners vessel london rode band fleet march arrows village marched boats gate resistance officer vessels officers armed coast presently advanced deck hills council count sail parties port forest leader desperate island\n",
      "\n",
      "Topic #3:\n",
      "jack king prince bill ha queen arrows camp thou palace em mill yellow ye village indian mountain pine band cat court toward giant majesty rode girls beast rock beauty presently ride bears warning castle marry doctor city forest wolf mountains ain ship pipes sister ring john lads thee dogs bull\n",
      "\n",
      "Topic #4:\n",
      "de mamma papa frank project king vi ship flower doctor sweet village deck shore aunt girls baby sister presently army toward darling works officers remarked towards city camp vessel coast tea attack ride prince loved london boats kiss dr garden officer ladies forest uncle obey grace south native french troops\n",
      "\n",
      "Topic #5:\n",
      "girls doctor papa mamma sister baby aunt sweet london dr street flower george tea yer darling tom cousin presently project loved uncle nurse ladies everybody flowers carriage de stairs mary ma wasn ain lovely gray remarked purse vi shop garden sisters christmas doesn rooms church bell st study em train\n",
      "\n",
      "Topic #6:\n",
      "august snow king swallow project city church dick garden uncle mountains painted heaven ship soldiers golden sold doctor prince towards works ice flowers army knife birds loved mountain bridge brothers noble music tom sweet lads court de giant ay murmured huge shore london village train wooden pole john wheel faith\n",
      "\n",
      "Topic #7:\n",
      "french troops officers attack guns army doctor officer jack tom camp regiment village soldiers british towards fort rode wounded dick ship james march native lads king column boats fired shore advanced marched mounted ride soldier rear stream attacked bush firing spanish prisoner governor presently prisoners count valley tent deck expedition\n",
      "\n",
      "Topic #8:\n",
      "de er den ain uncle yer wolf un jack folks gun lion dish tail sing jump aunt seed study goodness bag meat win fish fix woods king eve nigh rock fool song fur ha butter somebody john outer deer bull bird ho patch fuss tie bushes responded baby ma leg\n",
      "\n",
      "Topic #9:\n",
      "project doctor ye towards works shore island deck ship indian em foundation youth lake ice observed fish camp vessel tom ain mate public office gun james remarked boats agreement considerable reader states crew london ay snow cabin street regard demanded south study knife rock hut hero ma united tail sailor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# solution 2\n",
    "\n",
    "# Vectorize our text using CountVectorizer\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.80, min_df=50,\n",
    "                                max_features=None)\n",
    "                                #stop_words='english')\n",
    "\n",
    "dtm = tf_vectorizer.fit_transform(df_lit.text)\n",
    "print(\"Done!\")\n",
    "\n",
    "vocab = tf_vectorizer.get_feature_names_out() # save terms in vectorizer for later use \n",
    "\n",
    "n_samples = 2000\n",
    "n_topics = 10\n",
    "n_top_words = 50\n",
    "\n",
    "print(\"Fitting LDA model with tf features, \"\n",
    "      \"n_samples=%d and n_topics=%d...\"\n",
    "      % (n_samples, n_topics))\n",
    "\n",
    "#define the lda function, with desired options\n",
    "#Check the documentation, linked above, to look through the options\n",
    "lda_new = LDA(n_components=n_topics, \n",
    "          max_iter=20,\n",
    "          learning_method='online',\n",
    "          learning_offset=80.,\n",
    "          total_samples=n_samples,\n",
    "          random_state=0)\n",
    "\n",
    "#fit the model\n",
    "lda_new.fit(dtm)\n",
    "print(\"Done!\")\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "print_top_words(lda_new, vocab, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "Done!\n",
      "Fitting LDA model with tf features, n_samples=2000 and n_topics=10...\n",
      "Done!\n",
      "\n",
      "Topics in LDA model:\n",
      "\n",
      "Topic #0:\n",
      "romans walter percy roman titus simon major jews steamer jerusalem temple mary edward pierson ralph tug troops knight rome pilot archers commander knights leopard breaker martha geoffrey siege engine horatio followers galilee homer slain tiberias fort defenders towns defense france engineer leaders jew towers jewish inner tower cities palace assailants\n",
      "\n",
      "Topic #1:\n",
      "harry troops colonel frank regiment gutenberg tim project rupert cavalry malcolm ned natives fort tom charlie castle reginald sam fleet tm france infantry steamer walter column garrison earl duke sergeant governor indians spanish richard major hannibal alan siege william jim charles spaniards lieutenant artillery regiments irish troop pilot peter dick\n",
      "\n",
      "Topic #2:\n",
      "fred pa max primrose kenneth jasmine daisy samson poppy ma ta nat godfrey scar dove markham forrester colonel hannah chum grocery ken laddie arthur flint maister dirk grey gutenberg pink na mansion manor donald dredge project minister noo liver rod sarah forester castle fush aren shillings watter pipes _the palace\n",
      "\n",
      "Topic #3:\n",
      "ned francis edmund danes saxons venice genoese galleys dragon francisco signor luke danish sankey saxon fleet alfred vessels galley thou maria merchant genoa vor charlie rowed venetian admiral daughters maister rowing hammond pirates arrows lucy venetians polly paris canal mather chioggia republic doan feyther wi machinery assuredly planks tomorrow dagger\n",
      "\n",
      "Topic #4:\n",
      "amuba jethro egypt ameres egyptians gods egyptian rebu gertrude temple priest sacred gray ruth georgie chariot chariots marian arrows priests temples slaves rushes crocodile newport captives berry religion slave nile bubastes frank priesthood worship footmen troops palace cats spears causeway inclosure labor villages waterfowl honor peasants overheard tomb boatmen nation\n",
      "\n",
      "Topic #5:\n",
      "ronald reuben jimmy gutenberg indians project rooney tom maggie rifle murray eskimo ian jim arrows tm apaches beaver ruth blacks eskimos armstrong natives mary milly cattle victor savages joe apache spear alf trail bears kaffirs warriors wizard pine ralph malcolm squire um gyp sam buffalo tony sledge braves rifles rangers\n",
      "\n",
      "Topic #6:\n",
      "gutenberg project lulu annie papa mamma max tm princess elsie hester peter katy tom aunt smith violet maurice nigel zoe dora jo joe edward phil clover grandfather earl dinsmore electronic foundation professor nan vi gracie jesus fred hermit billy palace fairy lumley moses toby gray ob dan ned christmas thou\n",
      "\n",
      "Topic #7:\n",
      "dick tom bob major dave squire arthur robin temple kate billy solomon gregory pledge marion marston excitedly cable splash yer net georgie fen punt stumps cob wheelwright sam morgan philip monkey francis chap yow jungle steamer bait dam reeds farmer malays nat theer grey fisherman den mansfield uncles cliff wi\n",
      "\n",
      "Topic #8:\n",
      "en brer dat er rabbit ter dey fer fox den bob ole dar yer wid im git des bin wolf um dis ef tuck roun da gwine helen dem waller ar yo kin dan lak bout atter mo fo holler ez sez roberts whar sorter honey bimeby twel ali malay\n",
      "\n",
      "Topic #9:\n",
      "polly dory stephen oliver wyndham percy ben arthur pearl parson pepper joel helen term fifth jasper dig willoughby sixth schoolhouse maggie senior saint twitter david forrester awfully steamer skipper cheers frog junior cricket reader bramble club cameron bobby cad van ma juniors paul jonah aunt mammy maria fag hullo tom\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# solution 3\n",
    "\n",
    "# Vectorize our text using CountVectorizer\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.50, min_df=3,\n",
    "                                max_features=None, \n",
    "                                stop_words='english')\n",
    "\n",
    "dtm = tf_vectorizer.fit_transform(df_lit.text)\n",
    "print(\"Done!\")\n",
    "\n",
    "vocab = tf_vectorizer.get_feature_names_out() # save terms in vectorizer for later use \n",
    "\n",
    "n_samples = 2000\n",
    "n_topics = 10\n",
    "n_top_words = 50\n",
    "\n",
    "print(\"Fitting LDA model with tf features, \"\n",
    "      \"n_samples=%d and n_topics=%d...\"\n",
    "      % (n_samples, n_topics))\n",
    "\n",
    "#define the lda function, with desired options\n",
    "#Check the documentation, linked above, to look through the options\n",
    "lda_new = LDA(n_components=n_topics, \n",
    "          max_iter=20,\n",
    "          learning_method='online',\n",
    "          learning_offset=80.,\n",
    "          total_samples=n_samples,\n",
    "          random_state=0)\n",
    "\n",
    "#fit the model\n",
    "lda_new.fit(dtm)\n",
    "print(\"Done!\")\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "print_top_words(lda_new, vocab, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document-by-topic distribution <a id='topics'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "Done!\n",
      "Fitting LDA model with tf features, n_samples=2000 and n_topics=4...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Vectorize our text using CountVectorizer\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.80, min_df=50,\n",
    "                                max_features=None, \n",
    "                                stop_words='english')\n",
    "\n",
    "dtm = tf_vectorizer.fit_transform(df_lit.text)\n",
    "print(\"Done!\")\n",
    "\n",
    "vocab = tf_vectorizer.get_feature_names_out() # save terms in vectorizer for later use \n",
    "\n",
    "n_samples = 2000\n",
    "n_topics = 4\n",
    "n_top_words = 50\n",
    "\n",
    "print(\"Fitting LDA model with tf features, \"\n",
    "      \"n_samples=%d and n_topics=%d...\"\n",
    "      % (n_samples, n_topics))\n",
    "\n",
    "#define the lda function, with desired options\n",
    "#Check the documentation, linked above, to look through the options\n",
    "lda = LDA(n_components=n_topics, \n",
    "          max_iter=20,\n",
    "          learning_method='online',\n",
    "          learning_offset=80.,\n",
    "          total_samples=n_samples,\n",
    "          random_state=0)\n",
    "\n",
    "#fit the model\n",
    "lda.fit(dtm)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the topic distribution array\n",
    "topic_dist = lda.transform(dtm)\n",
    "\n",
    "# Merge back in with the original dataframe\n",
    "topic_dist_df = pd.DataFrame(topic_dist)\n",
    "df_w_topics = topic_dist_df.join(df_lit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "- What is the average topic weight by author gender, for each topic?\n",
    "- Which topic is most represented in texts by women? Most represented in texts by men?\n",
    "- Which topic is least represented in texts by women? Least represented in texts by men?\n",
    "- Graph these results.\n",
    "\n",
    "Hint 1: Consider using the python `range` function and a for-loop to create a list of topic indices and inspect average topic weights. This code block gets that started for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "topic_columns = range(0,4)\n",
    "for num in topic_columns:\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint 2: Use a Pandas `groupby()` to compare the topic loadings of Male and Female authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "author gender\n",
      "Female    0.653199\n",
      "Male      0.323377\n",
      "Name: 0, dtype: float64\n",
      "1\n",
      "author gender\n",
      "Female    0.127721\n",
      "Male      0.189827\n",
      "Name: 1, dtype: float64\n",
      "2\n",
      "author gender\n",
      "Female    0.157666\n",
      "Male      0.326972\n",
      "Name: 2, dtype: float64\n",
      "3\n",
      "author gender\n",
      "Female    0.061414\n",
      "Male      0.159824\n",
      "Name: 3, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#solution\n",
    "grouped = df_w_topics.groupby(\"author gender\")\n",
    "for num in topic_columns:\n",
    "    print(num)\n",
    "    print(grouped[num].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig1 = plt.figure()\n",
    "chrt = 0\n",
    "for num in topic_columns:\n",
    "    chrt += 1 \n",
    "    ax = fig1.add_subplot(2,3, chrt)\n",
    "    grouped[num].mean().plot(\n",
    "        kind = 'bar', \n",
    "        yerr = grouped[num].std(), \n",
    "        ylim=0, ax=ax, title=num)\n",
    "\n",
    "fig1.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA as dimensionality reduction <a id='dimensionality'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "from scipy import spatial\n",
    "\n",
    "dwm = df_w_topics.iloc[:,:4] # limit docs/topics DF to only topic weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Calculate the cosine similarity between the first book and all other books. What is the most similar book to the first one?\n",
    "\n",
    "_Hint 1:_ Use the `df.iterrows()` method to iterate over all rows in the document/topic weights DataFrame we just made. \n",
    "\n",
    "_Hint 2:_ To store the similarities, consider using a Python dictionary&mdashthat is, a list of key-value pairs. `max()` will get you the highest entry in the dictionary, and `dict.values()` will get you the dictionary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarities...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# solution\n",
    "\n",
    "first_book = dwm.iloc[0,:] # separate out topic weights for first book\n",
    "\n",
    "similarities = {} # initialize dictionary\n",
    "\n",
    "print(\"Computing similarities...\")\n",
    "for book_idx, row in dwm.iloc[1:,].iterrows(): # loop over rows after first row, as we're comparing all books to first one\n",
    "    sim = 1-spatial.distance.cosine(first_book, row)\n",
    "    similarities[book_idx] = sim\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a score of 0.99912,\n",
      "the most similar book to 'A Dog with a Bad Name' is:\n",
      "'A House Party, Don Gesualdo, and A Rainy June'\n"
     ]
    }
   ],
   "source": [
    "# Get similarity and index of most similar book\n",
    "max_sim = max(similarities.values())\n",
    "max_idx = max(similarities, key = similarities.get)\n",
    "\n",
    "# Print the results\n",
    "print(\"With a score of \" + str(round(max_sim,5)) + \",\")\n",
    "print(\"the most similar book to '\" + df_lit[\"title\"].iloc[0] + \"' is:\")\n",
    "print(\"'\" + df_lit[\"title\"].iloc[max_idx] + \"'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
