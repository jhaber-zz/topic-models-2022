{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Topic Modeling\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "### Version A\n",
    "* Implement a basic topic modeling algorithm and learn how to tweak it\n",
    "* Learn how to use different methods to calculate topic prevalence\n",
    "* Learn how to create some simple graphs with this output\n",
    "* Think through how and why you might use topic modeling in a text analysis project\n",
    "\n",
    "### Version B\n",
    "\n",
    "* Understand the DTM and why it's important to text analysis\n",
    "* Learn how to create a DTM in Python\n",
    "* Learn basic functionality of Python's package scikit-learn\n",
    "* Understand tf-idf scores\n",
    "* Learn a simple way to identify distinctive words\n",
    "* Implement a basic topic modeling algorithm and learn how to tweak it\n",
    "* In the process, gain more familiarity and comfort with the Pandas package and manipulating data\n",
    "\n",
    "### Version C\n",
    "\n",
    "* Understood that Latent Dirichlet Allocation (LDA) is one type of topic modeling\n",
    "* Loaded and saved the cleaned tokens into a Gensim corpus dictionary\n",
    "* Created a bag-of-words (BoW) corpus\n",
    "* Looked at Term Frequency–Inverse Document Frequency (TF-IDF)\n",
    "* Trained a Latent Dirichlet Allocation (LDA) topic model\n",
    "* Visualised the resulting topics with pyLDAvis\n",
    "\n",
    "\n",
    "## Outline\n",
    "- [What is topic modeling?](#whatis)\n",
    "    - [How LDA works (briefly)](#mechanics)\n",
    "- [How to join in with coding](#joinin)\n",
    "- [The Pandas dataframe: Children's literature](#data)\n",
    "    - [Exploratory data analysis](#explore)\n",
    "- [Text preprocessing](#preprocess)\n",
    "- [Train a topic model with LDA](#train)\n",
    "- [Document-by-topic distribution](#topics)\n",
    "- [Words aligned with each topic](#words)\n",
    "- [Topic prevalence](#prevalence)\n",
    "- [Topics over time](#time)\n",
    "- [LDA as dimensionality reduction](#dimensions)\n",
    "- [Visualising topics with pyLDAvis](#viz)\n",
    "- [Evaluating the topic model](#eval)\n",
    "- [Resources and alternatives](#resources)\n",
    "\n",
    "## Key terms\n",
    "* *Document Term Matrix*:\n",
    "    * a matrix that describes the frequency of terms that occur in a collection of documents. In a document-term matrix, rows correspond to documents in the collection and columns correspond to terms.\n",
    "* *TF-IDF Scores*: \n",
    "    * short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.\n",
    "* *Topic Modeling*:\n",
    "    * A statistical model to uncover abstract topics within a text. It uses the co-occurrence fo words within documents, compared to their distribution across documents, to uncover these abstract themes. The output is a list of weighted words, which indicate the subject of each topic, and a weight distribution across topics for each document.\n",
    "    \n",
    "* *LDA*:\n",
    "    * Latent Dirichlet Allocation. A implementation of topic modeling that assumes a Dirichlet prior. It does not take document order into account, unlike other topic modeling algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is topic modeling? <a id='whatis'></a>\n",
    "\n",
    "Topic modeling is a _distant reading_ technique for finding structure in large collections of text, without actually reading everything by eye. If you have hundreds or thousands of documents and want to understand roughly what your corpus contains, then topic modeling may be for you.\n",
    "\n",
    "A topic modeling program finds the words that appear frequently together in a document and groups them together to form **topics**, which are mixtures of words that characterize the document's themes or underlying ideas. For example, one topic of this [Wikipedia article on black holes](https://en.wikipedia.org/wiki/Black_hole) is:\n",
    "\n",
    "* black, hole, mass, star\n",
    "\n",
    "![First picture of a supermassive black hole, captured in 2019](https://upload.wikimedia.org/wikipedia/commons/thumb/c/cf/Black_hole_-_Messier_87.jpg/320px-Black_hole_-_Messier_87.jpg \"First picture of a supermassive black hole, captured in 2019\")\n",
    "\n",
    "Not too surprising, but this topic does seem accurate on the face of it. What about a document that we are less familiar with? Here is a topic of a [speech made by John F. Kennedy at Rice University in 1962](https://er.jsc.nasa.gov/seh/ricetalk.htm):\n",
    "\n",
    "* space, new, year, man\n",
    "\n",
    "![Charles Conrad Jr., Apollo 12 Commander, examines the unmanned Surveyor III spacecraft on the Moon](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Surveyor_3-Apollo_12.jpg/274px-Surveyor_3-Apollo_12.jpg \"Charles Conrad Jr., Apollo 12 Commander, examines the unmanned Surveyor III spacecraft on the Moon\")\n",
    "\n",
    "This is Kennedy's famous 'we choose to go to the moon' speech. Notice that 'moon' is not in this topic; but the speech does cover the history of humankind's (\"man's\") endeavours and emphasises a forward-looking perspective (the \"new\"-ness of advancements).\n",
    "\n",
    "From these simplified examples, we can see that human intervention is still required to interpret what topics might 'mean'. Topic modeling is not magic; it is a tool that requires informed use and careful review, just like any other.\n",
    "\n",
    "In the humanities, topic modeling may be used to support different approaches to large text corpora, such as:\n",
    "\n",
    "* Survey a collection that is too big to read closely, e.g. [Computational Historiography: Data Mining in a Century of Classics Journals](http://www.perseus.tufts.edu/publications/02-jocch-mimno.pdf) (PDF)\n",
    "* Look at thematic trends over time in an archive, e.g. [Topic Modeling Martha Ballard's Diary](http://www.cameronblevins.org/posts/topic-modeling-martha-ballards-diary/)\n",
    "* Create metadata for an archive to improve accessibility, e.g. [Topic modeling for the valorisation of digitised archives of the European Commission](https://ieeexplore.ieee.org/abstract/document/7840981)\n",
    "* Understand current trends in social media relevant to your discipline, e.g. [Mining the Open Web with ‘Looted Heritage’](https://electricarchaeology.ca/2012/06/08/mining-the-open-web-with-looted-heritage-draft/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How LDA works (briefly) <a id='mechanics'></a>\n",
    "\n",
    "We'll implement the original and simplest topic modeling algorithm, Latent Dirichlet Allocation (or LDA), using Python's scikit-learn. There is a lot to learn about topic modeling, but the focus here is giving you starter code you can expand on later. To give a little more mathematical context, though, here are the mechanics of this version of topic modeling. \n",
    "\n",
    "LDA is a generative model&mdash;a model of the data-generating process&mdash;in which documents are mixtures of topics and topics are probability distributions over tokens in the vocabulary. The (normalized) frequency of word $j$ in document $i$ can be written as:\n",
    "\n",
    "$q_{ij} = v_{i1}*\\theta_{1j} + v_{i2}*\\theta_{2j} + ... + v_{iK}*\\theta_{Kj}$\n",
    "\n",
    "where K is the total number of topics, $\\theta_{kj}$ is the probability that word $j$ shows up in topic $k$ and $v_{ik}$ is the weight assigned to topic $k$ in document $i$. The model treats $v$ and $\\theta$ as generated from Dirichlet-distributed priors and estimates them with Maximum Likelihood or Bayesian methods.\n",
    "\n",
    "$^1$ Reference: Blei, D. M., A. Y. Ng, and M. I. Jordan (2003). Latent Dirichlet allocation. Journal of Machine\n",
    "Learning Research 3, 993–1022."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## How to join in with coding <a id='joinin'></a>\n",
    "\n",
    "* **Edit** any cell and try changing the code, or delete it and write your own.\n",
    "\n",
    "* Before running a cell, think through the code and try to **guess** what output you'll get.\n",
    "\n",
    "* If you encounter an **error**, take a breath; this is normal. Errors happen all the time, and by reading the error message you will often learn something new and useful.\n",
    "\n",
    "* Remember: we are in the cloud, so you cannot break the notebook or your computer: **don't be afraid to experiment!**.\n",
    "\n",
    "**Let's get coding!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pandas dataframe: Children's literature <a id='data'></a>\n",
    "\n",
    "As our toy dataset, let's use a database of children's literature from the 19th century. The data were compiled by students in [this course](http://english197s2015.pbworks.com/w/page/93127947/FrontPage) and have been minimally cleaned for our use. The data and other corpora can be [found here](http://dhresourcesforprojectbuilding.pbworks.com/w/page/69244469/Data%20Collections%20and%20Datasets#demo-corpora), feel free to explore that data and play with it using text analysis!\n",
    "\n",
    "First, we read our corpus into a Pandas dataframe. The file is stored as a compressed .csv file in the `day-1/` folder, so we tell Pandas the compression type (`.bz2`) so it can unpack and read it for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author gender</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Dog with a Bad Name</td>\n",
       "      <td>Male</td>\n",
       "      <td>1886</td>\n",
       "      <td>A DOG WITH A BAD NAME  BY TALBOT BAINES REED  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Final Reckoning</td>\n",
       "      <td>Male</td>\n",
       "      <td>1887</td>\n",
       "      <td>A Final Reckoning: A Tale of Bush Life in Aust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A House Party, Don Gesualdo, and A Rainy June</td>\n",
       "      <td>Female</td>\n",
       "      <td>1887</td>\n",
       "      <td>A HOUSE-PARTY  Don Gesualdo  and  A Rainy June...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Houseful of Girls</td>\n",
       "      <td>Female</td>\n",
       "      <td>1889</td>\n",
       "      <td>A HOUSEFUL OF GIRLS. BY SARAH TYTLER,  AUTHOR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Little Country Girl</td>\n",
       "      <td>Female</td>\n",
       "      <td>1885</td>\n",
       "      <td>LITTLE COUNTRY GIRL.  BY  SUSAN COOLIDGE,     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Up the River</td>\n",
       "      <td>Male</td>\n",
       "      <td>1881</td>\n",
       "      <td>UP THE RIVER  OR  YACHTING ON THE MISSISSIPPI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>What Katy Did Next</td>\n",
       "      <td>Female</td>\n",
       "      <td>1886</td>\n",
       "      <td>WHAT KATY DID NEXT  BY  SUSAN COOLIDGE    This...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Winning His Spurs</td>\n",
       "      <td>Male</td>\n",
       "      <td>1882</td>\n",
       "      <td>WINNING HIS SPURS            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>With Clive in India</td>\n",
       "      <td>Male</td>\n",
       "      <td>1884</td>\n",
       "      <td>WITH CLIVE IN INDIA:  Or, The Beginnings of an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>With Wolfe in Canada</td>\n",
       "      <td>Male</td>\n",
       "      <td>1887</td>\n",
       "      <td>\\n WITH WOLFE IN CANADA  Or The Winning of a C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title author gender  year  \\\n",
       "0                            A Dog with a Bad Name          Male  1886   \n",
       "1                                A Final Reckoning          Male  1887   \n",
       "2    A House Party, Don Gesualdo, and A Rainy June        Female  1887   \n",
       "3                              A Houseful of Girls        Female  1889   \n",
       "4                            A Little Country Girl        Female  1885   \n",
       "..                                             ...           ...   ...   \n",
       "127                                   Up the River          Male  1881   \n",
       "128                             What Katy Did Next        Female  1886   \n",
       "129                              Winning His Spurs          Male  1882   \n",
       "130                            With Clive in India          Male  1884   \n",
       "131                           With Wolfe in Canada          Male  1887   \n",
       "\n",
       "                                                  text  \n",
       "0    A DOG WITH A BAD NAME  BY TALBOT BAINES REED  ...  \n",
       "1    A Final Reckoning: A Tale of Bush Life in Aust...  \n",
       "2    A HOUSE-PARTY  Don Gesualdo  and  A Rainy June...  \n",
       "3    A HOUSEFUL OF GIRLS. BY SARAH TYTLER,  AUTHOR ...  \n",
       "4    LITTLE COUNTRY GIRL.  BY  SUSAN COOLIDGE,     ...  \n",
       "..                                                 ...  \n",
       "127  UP THE RIVER  OR  YACHTING ON THE MISSISSIPPI ...  \n",
       "128  WHAT KATY DID NEXT  BY  SUSAN COOLIDGE    This...  \n",
       "129                   WINNING HIS SPURS            ...  \n",
       "130  WITH CLIVE IN INDIA:  Or, The Beginnings of an...  \n",
       "131  \\n WITH WOLFE IN CANADA  Or The Winning of a C...  \n",
       "\n",
       "[127 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_lit = pd.read_csv(\"data/childrens_lit.csv.bz2\", sep='\\t', index_col=0, encoding = 'utf-8', compression='bz2')\n",
    "\n",
    "#drop rows where the text is missing.\n",
    "df_lit = df_lit.dropna(subset=['text'])\n",
    "\n",
    "#view the dataframe\n",
    "df_lit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data <a id='explore'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some descriptive statistics about this dataset, to get a feel for what's in it and check for any visible errors. This will help with interpreting the data and knowing what kinds of questions to ask. \n",
    "\n",
    "The first thing most people do is to `describe` their data. (This is the `summary` command in R, or the `sum` command in Stata)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>127.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1885.110236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.752281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1880.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1883.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1886.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1887.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1889.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              year\n",
       "count   127.000000\n",
       "mean   1885.110236\n",
       "std       2.752281\n",
       "min    1880.000000\n",
       "25%    1883.000000\n",
       "50%    1886.000000\n",
       "75%    1887.000000\n",
       "max    1889.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There's only one numeric column in our data ('year'), so we only get one column for output.\n",
    "df_lit.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize the distribution of the 'year' column\n",
    "import matplotlib\n",
    "df_lit['year'].hist(bins = 10, grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the breakdown of author genders in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      99\n",
       "Female    28\n",
       "Name: author gender, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can count this using the value_counts() function\n",
    "df_lit['author gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author gender</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>127</td>\n",
       "      <td>2</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>A Dog with a Bad Name</td>\n",
       "      <td>Male</td>\n",
       "      <td>A DOG WITH A BAD NAME  BY TALBOT BAINES REED  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        title author gender  \\\n",
       "count                     127           127   \n",
       "unique                    127             2   \n",
       "top     A Dog with a Bad Name          Male   \n",
       "freq                        1            99   \n",
       "\n",
       "                                                     text  \n",
       "count                                                 127  \n",
       "unique                                                127  \n",
       "top     A DOG WITH A BAD NAME  BY TALBOT BAINES REED  ...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This only gets us numerical summaries. To get summaries of some of the other columns, we can explicitly ask for it.\n",
    "df_lit.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of titles do these books have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A Dog with a Bad Name                            1\n",
       "The Cornet of Horse                              1\n",
       "The Lion of Saint Mark                           1\n",
       "The Life of a Ship                               1\n",
       "The Land of Mystery                              1\n",
       "The Island Queen                                 1\n",
       "The Happy Prince and Other Stories               1\n",
       "The Gold of Fairnilee                            1\n",
       "The Giant of the North Pokings Round the Pole    1\n",
       "The Fugitives the Tyrant Queen of Madagascar     1\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lit['title'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the average year for each author gender? To answer this question, we use the powerful `groupby` function in Pandas. (Similar to `collapse` on Stata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author gender\n",
       "Female    1885.250000\n",
       "Male      1885.070707\n",
       "Name: year, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_grouped_by_gender = df_lit.groupby(\"author gender\")\n",
    "books_grouped_by_gender['year'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing <a id='preprocess'></a>\n",
    "\n",
    ">**The key to understanding Natural Language Processing (NLP) is that the computer can only do computations on _numbers_. We have to present our corpus for analysis in a numerical form&mdash;typically _vectors_&mdash;and make human sense of everything at the end.**\n",
    "\n",
    "A \"bag of words\" corpus is the _vocabulary_ of tokens (words) in the corpus together with some _measure_ of how often they occur. The measurement may be:\n",
    "* binary (presence or absence)\n",
    "* count (how many times the token occurs)\n",
    "* frequency (count divided by the total number of tokens).\n",
    "\n",
    "This is called a \"bag of words\" because the order and location of words is discarded. For example, it doesn't matter if the words 'red' and 'nose' are adjacent ('red nose'), or at the beginning or end of a sentence; this approach just treats the words individually. It's like a 'bag' of Scrabble™ tiles, where each tile is a word, all rattling around together in no particular order.\n",
    "\n",
    "To turn our texts into numbers, let's use the `CountVectorizer` function from `scikit-learn`. This transforms the text into a Document-Term Matrix (DTM), where each text is a row and each word is a column. In other words, each document becomes a _vector_ of word frequencies with a value for the count of each word in that document. This is also called Term Frequency (TF) weighting, representing each text by its word counts&mdash;probably the most straightforward method of preparing text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Vectorize our text using CountVectorizer\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.80, min_df=50,\n",
    "                                max_features=None,\n",
    "                                stop_words='english'\n",
    "                                )\n",
    "\n",
    "dtm = tf_vectorizer.fit_transform(df_lit.text)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the DTM we just made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<127x3197 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 229602 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This format is called Compressed Sparse Format. It saves a lot of memory to store the DTM in this format, but it is difficult to look at for a human. For illustration purposes, let's convert this matrix back to a Pandas DataFrame, a more understandable format. For larger datasets, you will have to use the Compressed Sparse Format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhaber/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "      <th>30</th>\n",
       "      <th>50</th>\n",
       "      <th>_you_</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>ability</th>\n",
       "      <th>abode</th>\n",
       "      <th>abreast</th>\n",
       "      <th>...</th>\n",
       "      <th>yelling</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yells</th>\n",
       "      <th>yer</th>\n",
       "      <th>yield</th>\n",
       "      <th>yielded</th>\n",
       "      <th>yonder</th>\n",
       "      <th>york</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  10  20  30  50  _you_  abandoned  ability  abode  abreast  ...  \\\n",
       "0    0   1   0   1   0      7          0        0      1        0  ...   \n",
       "1    0   2   4   1   1      0          2        1      2        2  ...   \n",
       "2    0   1   0   0   0      2          0        1      1        0  ...   \n",
       "3    0   0   1   0   0      3          3        6      0        0  ...   \n",
       "4    0   0   0   0   0      0          0        0      0        1  ...   \n",
       "\n",
       "   yelling  yellow  yells  yer  yield  yielded  yonder  york  youngest  youth  \n",
       "0        1       1      2    0      0        5       1    23         1     14  \n",
       "1        1       0      2    2      0        0       0     0         0      2  \n",
       "2        0       6      0    0      0        2       3     0         1     13  \n",
       "3        1       2      0    0      1        4       0     0         7     13  \n",
       "4        0      16      0    0      1        0       1     4         3      1  \n",
       "\n",
       "[5 rows x 3197 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_dtm = pd.DataFrame(dtm.toarray(), \n",
    "                        columns=tf_vectorizer.get_feature_names_out(), \n",
    "                        index=df_lit.index)\n",
    "long_dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a long-format DTM to quickly identify the most frequent words in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doctor     5032\n",
       "dick       4857\n",
       "king       4490\n",
       "jack       3787\n",
       "uncle      3680\n",
       "tom        3199\n",
       "ship       2762\n",
       "project    2738\n",
       "army       2735\n",
       "french     2677\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_dtm.sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most frequent words for male and female authors?\n",
    "\n",
    "#### TO DO: Add solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "* Print out the most infrequent words rather than the most frequent words. You can look at the [Pandas documentation](http://pandas.pydata.org/pandas-docs/stable/api.html#api-dataframe-stats) for more information.\n",
    "* Print the average number of times each word is used in a review.\n",
    "* Print this out sorted from highest to lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO: Add solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a topic model using LDA <a id='train'></a>\n",
    "\n",
    "The first thing we need to do is 'train a model'. These words and concepts come from the (fashionable!) sphere of **machine learning**. A 'model' is a simplified representation of something in the real world that a computer can handle. In topic modeling, the model is a representation of the topics of the corpus.\n",
    "\n",
    "We can say the computer acquires 'experience', or a simplified 'understanding' of what the corpus is about by creating a model of it. We have to train the computer in how to make its model by feeding it training data&mdash;in the case of topic modeling, this data is the text we are interested in.\n",
    "\n",
    "Let's train the model using the `scikit-learn` function `LatentDirichletAllocation`. See [here](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html) for more information about this function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "n_samples = 2000\n",
    "n_topics = 4\n",
    "n_top_words = 50\n",
    "\n",
    "##This is a function to print out the top words for each topic in a pretty way.\n",
    "#Don't worry too much about understanding every line of this code.\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LDA model with tf features, n_samples=2000 and n_topics=4...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting LDA model with tf features, \"\n",
    "      \"n_samples=%d and n_topics=%d...\"\n",
    "      % (n_samples, n_topics))\n",
    "\n",
    "#define the lda function, with desired options\n",
    "#Check the documentation, linked above, to look through the options\n",
    "lda = LDA(n_components=n_topics, \n",
    "          max_iter=20,\n",
    "          learning_method='online',\n",
    "          learning_offset=80.,\n",
    "          total_samples=n_samples,\n",
    "          random_state=0)\n",
    "#fit the model\n",
    "lda.fit(dtm)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model:\n",
      "\n",
      "Topic #0:\n",
      "project doctor girls sister papa mamma london baby sweet tom street works dr remarked aunt tea youth foundation presently study em ain cousin office darling loved ladies wasn everybody public flower observed nurse ma shop snow ye queen class reader ice stairs flowers lovely agreement sisters doesn carriage bell garden\n",
      "\n",
      "Topic #1:\n",
      "dick uncle doctor er jack ain tom den yer fish em rock wolf gun rope lads ha birds rocks beneath ay stream shock tail moments mate excitedly garden eh sand fishing thrust ye nay gazing softly mountain ship tremendous hook bird leg ashore growled penny shore stones farther jump knife\n",
      "\n",
      "Topic #2:\n",
      "king army french troops camp attack officers prince ship john soldiers city village officer guns rode shore regiment march tom fort wounded british boats sword advanced castle jack james indian band marched native prisoners ships arrows france numbers lads forest frank ride presently vessel fought mounted fleet column stream rear\n",
      "\n",
      "Topic #3:\n",
      "jack ye frank deck project uncle ship george shore doctor vessel ain mate lake cabin em ma st john works boats island officer girls passengers sail street church thou south office ha fish ay yer steam soldier ladies regard fleet camp public foundation rope lads illustration bottle pounds stairs crew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhaber/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#print the top words per topic, using the function defined above.\n",
    "#Unlike R, which has a built-in function to print top words, we have to write our own for scikit-learn\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names_out()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a minute to inspect these top words. _What name would you give each of these topics?_ (This is a common task in topic modeling.)\n",
    "\n",
    "> **❗Important Note: Topic models are not perfectly reproducible, so you may see different topics, words, and/or probabilities  from what others see. This means my examples may not match up exactly with what you see when you run the notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Copy and paste the above code and fit a new model, `lda_new`, by changing some of the parameters. How does this change the output?\n",
    "\n",
    "Suggestions:\n",
    "1. Change the number of topics. \n",
    "2. Do not remove stop words. \n",
    "3. Change other options, either in the vectorize stage or the LDA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document by Topic Distribution <a id='topics'></a>\n",
    "\n",
    "One thing we may want to do with the output is find the most representative texts for each topic. A simple way to do this (but not memory efficient) is to merge the topic distribution back into the Pandas dataframe.\n",
    "\n",
    "First get the topic distribution array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.27993669e-01, 1.43700382e-02, 5.76027691e-02, 3.35234006e-05],\n",
       "       [2.73383488e-02, 7.01313231e-02, 4.91328141e-01, 4.11202187e-01],\n",
       "       [9.72301526e-01, 3.66126075e-05, 2.25981325e-02, 5.06372922e-03],\n",
       "       [9.99907351e-01, 3.06661128e-05, 3.10550012e-05, 3.09277922e-05],\n",
       "       [9.69292227e-01, 2.88828433e-02, 6.05477628e-05, 1.76438162e-03],\n",
       "       [9.02818435e-01, 9.70583246e-02, 6.16743414e-05, 6.15656757e-05],\n",
       "       [4.10396600e-01, 5.86307314e-01, 1.35979768e-04, 3.16010688e-03],\n",
       "       [9.99890902e-01, 3.60980543e-05, 3.67128035e-05, 3.62872482e-05],\n",
       "       [2.46371338e-01, 2.56589766e-01, 4.50088248e-01, 4.69506480e-02],\n",
       "       [7.08481800e-05, 3.81086663e-01, 6.18771825e-01, 7.06641686e-05],\n",
       "       [6.19417246e-02, 5.60865999e-02, 8.81890242e-01, 8.14334923e-05],\n",
       "       [5.50253267e-05, 5.59319821e-05, 5.52375701e-05, 9.99833805e-01],\n",
       "       [1.54941895e-01, 8.53067338e-05, 1.95440934e-01, 6.49531864e-01],\n",
       "       [8.16413872e-01, 6.08089939e-02, 1.22708631e-01, 6.85031993e-05],\n",
       "       [6.29009722e-01, 4.21386866e-02, 2.54541577e-01, 7.43100148e-02],\n",
       "       [5.20390704e-01, 2.69891665e-05, 3.12178238e-01, 1.67404069e-01],\n",
       "       [2.59339206e-05, 2.54612217e-05, 9.99922584e-01, 2.60211864e-05],\n",
       "       [6.22435512e-03, 4.68816251e-05, 2.25767472e-02, 9.71152016e-01],\n",
       "       [3.87465852e-04, 9.99551674e-01, 3.01743230e-05, 3.06855502e-05],\n",
       "       [2.68953989e-05, 9.99919007e-01, 2.72168308e-05, 2.68810707e-05],\n",
       "       [2.69833700e-05, 2.80524034e-02, 7.49472949e-01, 2.22447664e-01],\n",
       "       [2.77889542e-05, 7.34069452e-02, 1.97857460e-01, 7.28707806e-01],\n",
       "       [9.97249650e-01, 6.12290209e-05, 1.11113084e-03, 1.57799044e-03],\n",
       "       [2.11005150e-03, 7.24263955e-01, 2.73601496e-01, 2.44968641e-05],\n",
       "       [2.23764047e-05, 9.99933009e-01, 2.22828683e-05, 2.23316258e-05],\n",
       "       [4.93753142e-05, 4.91020308e-05, 4.98451013e-05, 9.99851678e-01],\n",
       "       [9.92489652e-01, 1.86473736e-03, 1.54734276e-03, 4.09826791e-03],\n",
       "       [9.99882923e-01, 3.88701433e-05, 3.89527356e-05, 3.92542903e-05],\n",
       "       [9.99873970e-01, 4.19279277e-05, 4.18597810e-05, 4.22421685e-05],\n",
       "       [6.95185897e-04, 7.34312964e-03, 4.01273553e-03, 9.87948949e-01],\n",
       "       [8.75839693e-01, 1.24052565e-01, 5.41207288e-05, 5.36206171e-05],\n",
       "       [6.36222545e-01, 3.63720142e-01, 2.86381710e-05, 2.86742684e-05],\n",
       "       [2.95087877e-05, 2.95816598e-05, 9.99911112e-01, 2.97977155e-05],\n",
       "       [2.13256430e-05, 2.10559479e-05, 9.99936397e-01, 2.12209363e-05],\n",
       "       [2.52951451e-05, 2.47863102e-05, 9.99924710e-01, 2.52088689e-05],\n",
       "       [5.50178330e-01, 3.81124210e-05, 2.19143102e-01, 2.30640456e-01],\n",
       "       [9.99870242e-01, 4.29589552e-05, 4.32499132e-05, 4.35495588e-05],\n",
       "       [7.68274655e-01, 2.31587553e-01, 6.88908253e-05, 6.89012673e-05],\n",
       "       [3.02635323e-05, 3.00362899e-05, 2.28550285e-01, 7.71389415e-01],\n",
       "       [3.78348200e-01, 3.76726709e-05, 6.05171022e-01, 1.64431056e-02],\n",
       "       [2.48140562e-05, 1.14676837e-01, 8.85273702e-01, 2.46464918e-05],\n",
       "       [2.46288680e-05, 6.86021611e-02, 8.78430327e-01, 5.29428835e-02],\n",
       "       [6.96768549e-01, 1.61091998e-02, 2.48347032e-01, 3.87752187e-02],\n",
       "       [9.84724988e-01, 1.32514180e-02, 2.82458747e-05, 1.99534815e-03],\n",
       "       [9.48549600e-01, 2.17851043e-02, 4.99388846e-05, 2.96153565e-02],\n",
       "       [9.99432957e-01, 1.86591148e-04, 1.88885121e-04, 1.91566514e-04],\n",
       "       [6.44725935e-03, 1.15032272e-01, 1.39974344e-01, 7.38546124e-01],\n",
       "       [8.92880314e-01, 1.06990181e-01, 6.49862726e-05, 6.45187573e-05],\n",
       "       [2.79592490e-05, 9.99916066e-01, 2.79014504e-05, 2.80733658e-05],\n",
       "       [1.89458962e-05, 7.47291749e-01, 2.52670376e-01, 1.89295372e-05],\n",
       "       [2.47825533e-05, 9.68102678e-01, 2.02279090e-02, 1.16446302e-02],\n",
       "       [9.40573222e-01, 4.88573281e-02, 6.35625559e-05, 1.05058869e-02],\n",
       "       [6.43259582e-01, 1.48922683e-02, 2.49253922e-05, 3.41823224e-01],\n",
       "       [2.62163326e-05, 9.99921897e-01, 2.57379596e-05, 2.61491059e-05],\n",
       "       [2.75622380e-05, 2.72366214e-05, 9.99917589e-01, 2.76122315e-05],\n",
       "       [2.84026252e-05, 9.93662591e-01, 2.80940235e-05, 6.28091229e-03],\n",
       "       [6.04745270e-05, 5.95408446e-05, 5.84978728e-05, 9.99821487e-01],\n",
       "       [5.93806852e-02, 3.46949883e-05, 3.43401887e-05, 9.40550280e-01],\n",
       "       [9.99890704e-01, 3.67775412e-05, 3.61683120e-05, 3.63499455e-05],\n",
       "       [9.15079355e-01, 2.58967910e-05, 1.62305819e-02, 6.86641667e-02],\n",
       "       [3.57347337e-01, 1.41755892e-04, 6.42369659e-01, 1.41247656e-04],\n",
       "       [1.34751191e-01, 8.65194234e-01, 2.71253760e-05, 2.74492035e-05],\n",
       "       [8.18693885e-01, 4.46272497e-03, 1.76816512e-01, 2.68784146e-05],\n",
       "       [9.99607042e-01, 3.79842903e-05, 3.79466263e-05, 3.17027013e-04],\n",
       "       [9.78565311e-01, 2.09382720e-02, 2.48876622e-04, 2.47540480e-04],\n",
       "       [3.33633353e-01, 7.07487297e-02, 5.92078991e-01, 3.53892572e-03],\n",
       "       [1.56793327e-01, 6.90749086e-01, 2.54887811e-04, 1.52202700e-01],\n",
       "       [2.34909275e-05, 2.30992456e-05, 9.99930092e-01, 2.33182901e-05],\n",
       "       [1.24520919e-02, 6.07831844e-02, 7.03609668e-02, 8.56403757e-01],\n",
       "       [5.36809469e-05, 5.27821583e-05, 1.81841629e-01, 8.18051907e-01],\n",
       "       [1.62000362e-01, 2.70566965e-01, 5.66232408e-01, 1.20026461e-03],\n",
       "       [4.75872869e-01, 5.23997278e-01, 6.44584727e-05, 6.53940160e-05],\n",
       "       [5.11255638e-01, 6.63880256e-02, 1.29577789e-01, 2.92778547e-01],\n",
       "       [3.25555282e-01, 5.29041078e-05, 6.64877341e-01, 9.51447358e-03],\n",
       "       [6.74521206e-01, 3.94834898e-02, 2.82683303e-01, 3.31200138e-03],\n",
       "       [6.59971779e-01, 3.26800005e-01, 1.92630251e-04, 1.30355853e-02],\n",
       "       [4.47955889e-01, 2.07716120e-05, 5.52002729e-01, 2.06111200e-05],\n",
       "       [2.74230398e-05, 2.73114627e-05, 9.48652379e-01, 5.12928869e-02],\n",
       "       [3.24002453e-02, 2.43931794e-05, 9.67550760e-01, 2.46015027e-05],\n",
       "       [9.94149674e-01, 3.97325275e-05, 5.77114770e-03, 3.94457639e-05],\n",
       "       [5.07795452e-03, 2.60262231e-05, 9.94869727e-01, 2.62918616e-05],\n",
       "       [5.08686499e-01, 8.99641260e-02, 3.05305812e-01, 9.60435633e-02],\n",
       "       [3.63808909e-01, 3.12648813e-05, 5.60073674e-01, 7.60861521e-02],\n",
       "       [2.87962449e-05, 2.86650849e-05, 9.99913614e-01, 2.89245921e-05],\n",
       "       [6.44128252e-01, 1.62680401e-01, 1.00259212e-01, 9.29321352e-02],\n",
       "       [9.99914405e-01, 2.87026734e-05, 2.83997990e-05, 2.84923735e-05],\n",
       "       [5.96775142e-01, 2.53240034e-05, 4.03174376e-01, 2.51587580e-05],\n",
       "       [6.06937332e-01, 1.54511233e-01, 2.32583613e-01, 5.96782155e-03],\n",
       "       [2.52271767e-01, 2.30484781e-01, 2.10400343e-01, 3.06843109e-01],\n",
       "       [8.30419324e-01, 6.65000717e-02, 1.02893114e-01, 1.87490356e-04],\n",
       "       [6.57108783e-01, 1.21895883e-02, 1.59472791e-01, 1.71228837e-01],\n",
       "       [2.35593547e-01, 5.21793079e-02, 7.12186383e-01, 4.07624485e-05],\n",
       "       [5.07083732e-03, 2.12332011e-04, 2.11909485e-04, 9.94504921e-01],\n",
       "       [2.60719523e-05, 2.57156990e-05, 9.91388118e-01, 8.56009414e-03],\n",
       "       [2.33063082e-05, 2.31460419e-05, 9.99930270e-01, 2.32780864e-05],\n",
       "       [9.13593348e-01, 7.73206543e-02, 8.98878874e-03, 9.72093796e-05],\n",
       "       [3.50812124e-01, 5.86339435e-02, 6.90240031e-05, 5.90484908e-01],\n",
       "       [9.99903337e-01, 3.22304386e-05, 3.22208712e-05, 3.22113930e-05],\n",
       "       [8.38573910e-01, 1.60767632e-02, 1.22366608e-01, 2.29827186e-02],\n",
       "       [3.00244254e-02, 8.74038640e-01, 9.58471271e-02, 8.98078334e-05],\n",
       "       [9.99897778e-01, 3.38302806e-05, 3.40937077e-05, 3.42982466e-05],\n",
       "       [6.18421796e-01, 2.82558672e-02, 3.53277967e-01, 4.43698230e-05],\n",
       "       [3.66632194e-01, 1.67964686e-01, 4.65343321e-01, 5.97993334e-05],\n",
       "       [5.74429841e-01, 1.14779581e-01, 3.07629681e-01, 3.16089710e-03],\n",
       "       [2.98722530e-05, 7.80221211e-01, 2.19719235e-01, 2.96820595e-05],\n",
       "       [6.85523511e-01, 1.99822730e-01, 2.49746058e-04, 1.14404013e-01],\n",
       "       [7.07904733e-01, 3.67137105e-02, 2.07369327e-01, 4.80122293e-02],\n",
       "       [9.93605752e-01, 9.26695521e-05, 8.95035000e-05, 6.21207458e-03],\n",
       "       [9.99869696e-01, 4.34422188e-05, 4.32532342e-05, 4.36086232e-05],\n",
       "       [9.89787950e-01, 2.77545432e-05, 1.01567162e-02, 2.75792374e-05],\n",
       "       [4.69569319e-03, 3.84249969e-02, 9.56853604e-01, 2.57059858e-05],\n",
       "       [2.14651385e-05, 2.12966427e-05, 9.99935882e-01, 2.13565648e-05],\n",
       "       [3.21889729e-05, 1.32252402e-01, 8.67683173e-01, 3.22364414e-05],\n",
       "       [5.23945561e-01, 2.35792644e-02, 3.03667792e-05, 4.52444808e-01],\n",
       "       [3.47794382e-05, 9.99895593e-01, 3.46976144e-05, 3.49300271e-05],\n",
       "       [8.24753592e-05, 9.99750816e-01, 8.35146626e-05, 8.31942505e-05],\n",
       "       [4.28114427e-01, 1.87053683e-03, 1.33569490e-01, 4.36445546e-01],\n",
       "       [4.54667623e-03, 3.63829509e-01, 5.93609748e-02, 5.72262840e-01],\n",
       "       [5.37666487e-01, 1.82696997e-01, 2.16645746e-01, 6.29907702e-02],\n",
       "       [6.29197555e-02, 3.24250187e-01, 6.06466466e-01, 6.36359138e-03],\n",
       "       [3.39127111e-03, 9.96494489e-01, 5.63670954e-05, 5.78726307e-05],\n",
       "       [2.24936092e-05, 2.26005723e-05, 9.99932315e-01, 2.25905995e-05],\n",
       "       [4.71212890e-05, 4.68654488e-05, 4.78505333e-05, 9.99858163e-01],\n",
       "       [9.60204564e-01, 5.35638494e-05, 5.19090084e-03, 3.45509713e-02],\n",
       "       [2.58383298e-05, 2.54067521e-05, 9.99923113e-01, 2.56418862e-05],\n",
       "       [2.00457030e-05, 2.02350450e-05, 9.99939520e-01, 2.01988375e-05],\n",
       "       [2.23771449e-05, 2.23741816e-05, 9.67389742e-01, 3.25655066e-02]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_dist = lda.transform(dtm)\n",
    "topic_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge back in with the original dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>title</th>\n",
       "      <th>author gender</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.927994</td>\n",
       "      <td>0.014370</td>\n",
       "      <td>0.057603</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>A Dog with a Bad Name</td>\n",
       "      <td>Male</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>A DOG WITH A BAD NAME  BY TALBOT BAINES REED  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027338</td>\n",
       "      <td>0.070131</td>\n",
       "      <td>0.491328</td>\n",
       "      <td>0.411202</td>\n",
       "      <td>A Final Reckoning</td>\n",
       "      <td>Male</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>A Final Reckoning: A Tale of Bush Life in Aust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.972302</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.022598</td>\n",
       "      <td>0.005064</td>\n",
       "      <td>A House Party, Don Gesualdo, and A Rainy June</td>\n",
       "      <td>Female</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>A HOUSE-PARTY  Don Gesualdo  and  A Rainy June...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>A Houseful of Girls</td>\n",
       "      <td>Female</td>\n",
       "      <td>1889.0</td>\n",
       "      <td>A HOUSEFUL OF GIRLS. BY SARAH TYTLER,  AUTHOR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.969292</td>\n",
       "      <td>0.028883</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>A Little Country Girl</td>\n",
       "      <td>Female</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>LITTLE COUNTRY GIRL.  BY  SUSAN COOLIDGE,     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>Treasure Island</td>\n",
       "      <td>Male</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>TREASURE ISLAND  by Robert Louis Stevenson    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.960205</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>0.034551</td>\n",
       "      <td>Twice Bought</td>\n",
       "      <td>Male</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>The Project Gutenberg EBook of Twice Bought, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>Two Arrows</td>\n",
       "      <td>Male</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>TWO ARROWS      HARPER'S YOUNG PEOPLE'S SERIES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>Uncle Remus: His Songs and Sayings</td>\n",
       "      <td>Male</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>Uncle Remus: His Songs and His Sayings  By Joe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.967390</td>\n",
       "      <td>0.032566</td>\n",
       "      <td>Under Drake's Flag</td>\n",
       "      <td>Male</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>Under Drake's Flag:  A Tale of the Spanish Mai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3  \\\n",
       "0    0.927994  0.014370  0.057603  0.000034   \n",
       "1    0.027338  0.070131  0.491328  0.411202   \n",
       "2    0.972302  0.000037  0.022598  0.005064   \n",
       "3    0.999907  0.000031  0.000031  0.000031   \n",
       "4    0.969292  0.028883  0.000061  0.001764   \n",
       "..        ...       ...       ...       ...   \n",
       "122  0.000047  0.000047  0.000048  0.999858   \n",
       "123  0.960205  0.000054  0.005191  0.034551   \n",
       "124  0.000026  0.000025  0.999923  0.000026   \n",
       "125  0.000020  0.000020  0.999940  0.000020   \n",
       "126  0.000022  0.000022  0.967390  0.032566   \n",
       "\n",
       "                                             title author gender    year  \\\n",
       "0                            A Dog with a Bad Name          Male  1886.0   \n",
       "1                                A Final Reckoning          Male  1887.0   \n",
       "2    A House Party, Don Gesualdo, and A Rainy June        Female  1887.0   \n",
       "3                              A Houseful of Girls        Female  1889.0   \n",
       "4                            A Little Country Girl        Female  1885.0   \n",
       "..                                             ...           ...     ...   \n",
       "122                                Treasure Island          Male  1883.0   \n",
       "123                                   Twice Bought          Male  1885.0   \n",
       "124                                     Two Arrows          Male  1886.0   \n",
       "125             Uncle Remus: His Songs and Sayings          Male  1880.0   \n",
       "126                             Under Drake's Flag          Male  1883.0   \n",
       "\n",
       "                                                  text  \n",
       "0    A DOG WITH A BAD NAME  BY TALBOT BAINES REED  ...  \n",
       "1    A Final Reckoning: A Tale of Bush Life in Aust...  \n",
       "2    A HOUSE-PARTY  Don Gesualdo  and  A Rainy June...  \n",
       "3    A HOUSEFUL OF GIRLS. BY SARAH TYTLER,  AUTHOR ...  \n",
       "4    LITTLE COUNTRY GIRL.  BY  SUSAN COOLIDGE,     ...  \n",
       "..                                                 ...  \n",
       "122  TREASURE ISLAND  by Robert Louis Stevenson    ...  \n",
       "123  The Project Gutenberg EBook of Twice Bought, b...  \n",
       "124  TWO ARROWS      HARPER'S YOUNG PEOPLE'S SERIES...  \n",
       "125  Uncle Remus: His Songs and His Sayings  By Joe...  \n",
       "126  Under Drake's Flag:  A Tale of the Spanish Mai...  \n",
       "\n",
       "[127 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_dist_df = pd.DataFrame(topic_dist)\n",
    "df_w_topics = topic_dist_df.join(df_lit)\n",
    "df_w_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can sort the dataframe for the topic of interest, and view the top documents for the topics.\n",
    "Below we sort the documents first by Topic 0 (looking at the top words for this topic I think it's about family, health, and domestic activities), and next by Topic 1 (again looking at the top words I think this topic is about children playing outside in nature). These topics may be a family/nature split?\n",
    "\n",
    "Look at the titles for the two different topics. Look at the gender of the author. Hypotheses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  title author gender         0\n",
      "85                                  NaN           NaN  0.999914\n",
      "3                   A Houseful of Girls        Female  0.999907\n",
      "97                   The Life of a Ship          Male  0.999903\n",
      "100   The Little Princess of Tower Hill        Female  0.999898\n",
      "7                      A World of Girls        Female  0.999891\n",
      "..                                  ...           ...       ...\n",
      "24                     Dick o' the Fens          Male  0.000022\n",
      "111                The Thorogood Family          Male  0.000021\n",
      "33                       For the Temple          Male  0.000021\n",
      "125  Uncle Remus: His Songs and Sayings          Male  0.000020\n",
      "49                            Menhardoc          Male  0.000019\n",
      "\n",
      "[127 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_w_topics[['title', 'author gender', 0]].sort_values(by=[0], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  title author gender         1\n",
      "24                     Dick o' the Fens          Male  0.999933\n",
      "53                      My Friend Smith          Male  0.999922\n",
      "19                          Bunyip Land          Male  0.999919\n",
      "48               Little Lord Fauntleroy        Female  0.999916\n",
      "114             The Willoughby Captains          Male  0.999896\n",
      "..                                  ...           ...       ...\n",
      "126                  Under Drake's Flag          Male  0.000022\n",
      "111                The Thorogood Family          Male  0.000021\n",
      "33                       For the Temple          Male  0.000021\n",
      "76                        The Big Otter          Male  0.000021\n",
      "125  Uncle Remus: His Songs and Sayings          Male  0.000020\n",
      "\n",
      "[127 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_w_topics[['title', 'author gender', 1]].sort_values(by=[1], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "- What is the average topic weight by author gender, for each topic?\n",
    "- Which topic is most represented in texts by women? Most represented in texts by men?\n",
    "- Which topic is least represented in texts by women? Least represented in texts by men?\n",
    "- Graph these results.\n",
    "\n",
    "Hint 1: Consider using the python `range` function and a for-loop to create a list of topic indices and inspect average topic weights. This code block gets that started for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "topic_columns = range(0,4)\n",
    "for num in topic_columns:\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint 2: Use a Pandas `groupby()` to compare the topic loadings of Male and Female authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "author gender\n",
      "Female    0.653199\n",
      "Male      0.323377\n",
      "Name: 0, dtype: float64\n",
      "1\n",
      "author gender\n",
      "Female    0.127721\n",
      "Male      0.189827\n",
      "Name: 1, dtype: float64\n",
      "2\n",
      "author gender\n",
      "Female    0.157666\n",
      "Male      0.326972\n",
      "Name: 2, dtype: float64\n",
      "3\n",
      "author gender\n",
      "Female    0.061414\n",
      "Male      0.159824\n",
      "Name: 3, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#solution\n",
    "grouped = df_w_topics.groupby(\"author gender\")\n",
    "for num in topic_columns:\n",
    "    print(num)\n",
    "    print(grouped[num].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig1 = plt.figure()\n",
    "chrt = 0\n",
    "for num in topic_columns:\n",
    "    chrt += 1 \n",
    "    ax = fig1.add_subplot(2,3, chrt)\n",
    "    grouped[num].mean().plot(\n",
    "        kind = 'bar', \n",
    "        yerr = grouped[num].std(), \n",
    "        ylim=0, ax=ax, title=num)\n",
    "\n",
    "fig1.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words aligned with each topic <a id='words'></a>\n",
    "\n",
    "Let's calculate the total number of words aligned with each topic and compare by author gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       96493\n",
       "1      100603\n",
       "2       85132\n",
       "3       92822\n",
       "4       48251\n",
       "        ...  \n",
       "122     68589\n",
       "123     76593\n",
       "124     56018\n",
       "125     53942\n",
       "126    108275\n",
       "Name: word_count, Length: 127, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first create word count column\n",
    "\n",
    "df_w_topics['word_count'] = df_w_topics['text'].apply(lambda x: len(str(x).split()))\n",
    "df_w_topics['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      89544.893129\n",
       "1       2750.319905\n",
       "2      82773.973483\n",
       "3      92813.400143\n",
       "4      46769.319262\n",
       "           ...     \n",
       "122        3.232002\n",
       "123    73544.948175\n",
       "124        1.447412\n",
       "125        1.081305\n",
       "126        2.422885\n",
       "Name: 0_wc, Length: 127, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multiply topic weight by word count\n",
    "\n",
    "df_w_topics['0_wc'] = df_w_topics[0] * df_w_topics['word_count']\n",
    "df_w_topics['0_wc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>title</th>\n",
       "      <th>author gender</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>0_wc</th>\n",
       "      <th>1_wc</th>\n",
       "      <th>2_wc</th>\n",
       "      <th>3_wc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.927994</td>\n",
       "      <td>0.014370</td>\n",
       "      <td>0.057603</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>A Dog with a Bad Name</td>\n",
       "      <td>Male</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>A DOG WITH A BAD NAME  BY TALBOT BAINES REED  ...</td>\n",
       "      <td>96493</td>\n",
       "      <td>89544.893129</td>\n",
       "      <td>1386.608095</td>\n",
       "      <td>5558.264002</td>\n",
       "      <td>3.234773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027338</td>\n",
       "      <td>0.070131</td>\n",
       "      <td>0.491328</td>\n",
       "      <td>0.411202</td>\n",
       "      <td>A Final Reckoning</td>\n",
       "      <td>Male</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>A Final Reckoning: A Tale of Bush Life in Aust...</td>\n",
       "      <td>100603</td>\n",
       "      <td>2750.319905</td>\n",
       "      <td>7055.421499</td>\n",
       "      <td>49429.084933</td>\n",
       "      <td>41368.173663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.972302</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.022598</td>\n",
       "      <td>0.005064</td>\n",
       "      <td>A House Party, Don Gesualdo, and A Rainy June</td>\n",
       "      <td>Female</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>A HOUSE-PARTY  Don Gesualdo  and  A Rainy June...</td>\n",
       "      <td>85132</td>\n",
       "      <td>82773.973483</td>\n",
       "      <td>3.116905</td>\n",
       "      <td>1923.824216</td>\n",
       "      <td>431.085396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>A Houseful of Girls</td>\n",
       "      <td>Female</td>\n",
       "      <td>1889.0</td>\n",
       "      <td>A HOUSEFUL OF GIRLS. BY SARAH TYTLER,  AUTHOR ...</td>\n",
       "      <td>92822</td>\n",
       "      <td>92813.400143</td>\n",
       "      <td>2.846490</td>\n",
       "      <td>2.882587</td>\n",
       "      <td>2.870780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.969292</td>\n",
       "      <td>0.028883</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>A Little Country Girl</td>\n",
       "      <td>Female</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>LITTLE COUNTRY GIRL.  BY  SUSAN COOLIDGE,     ...</td>\n",
       "      <td>48251</td>\n",
       "      <td>46769.319262</td>\n",
       "      <td>1393.626070</td>\n",
       "      <td>2.921490</td>\n",
       "      <td>85.133178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>Treasure Island</td>\n",
       "      <td>Male</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>TREASURE ISLAND  by Robert Louis Stevenson    ...</td>\n",
       "      <td>68589</td>\n",
       "      <td>3.232002</td>\n",
       "      <td>3.214454</td>\n",
       "      <td>3.282020</td>\n",
       "      <td>68579.271523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.960205</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>0.034551</td>\n",
       "      <td>Twice Bought</td>\n",
       "      <td>Male</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>The Project Gutenberg EBook of Twice Bought, b...</td>\n",
       "      <td>76593</td>\n",
       "      <td>73544.948175</td>\n",
       "      <td>4.102616</td>\n",
       "      <td>397.586668</td>\n",
       "      <td>2646.362541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>Two Arrows</td>\n",
       "      <td>Male</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>TWO ARROWS      HARPER'S YOUNG PEOPLE'S SERIES...</td>\n",
       "      <td>56018</td>\n",
       "      <td>1.447412</td>\n",
       "      <td>1.423235</td>\n",
       "      <td>56013.692946</td>\n",
       "      <td>1.436407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>Uncle Remus: His Songs and Sayings</td>\n",
       "      <td>Male</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>Uncle Remus: His Songs and His Sayings  By Joe...</td>\n",
       "      <td>53942</td>\n",
       "      <td>1.081305</td>\n",
       "      <td>1.091519</td>\n",
       "      <td>53938.737610</td>\n",
       "      <td>1.089566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.967390</td>\n",
       "      <td>0.032566</td>\n",
       "      <td>Under Drake's Flag</td>\n",
       "      <td>Male</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>Under Drake's Flag:  A Tale of the Spanish Mai...</td>\n",
       "      <td>108275</td>\n",
       "      <td>2.422885</td>\n",
       "      <td>2.422565</td>\n",
       "      <td>104744.124318</td>\n",
       "      <td>3526.030232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3  \\\n",
       "0    0.927994  0.014370  0.057603  0.000034   \n",
       "1    0.027338  0.070131  0.491328  0.411202   \n",
       "2    0.972302  0.000037  0.022598  0.005064   \n",
       "3    0.999907  0.000031  0.000031  0.000031   \n",
       "4    0.969292  0.028883  0.000061  0.001764   \n",
       "..        ...       ...       ...       ...   \n",
       "122  0.000047  0.000047  0.000048  0.999858   \n",
       "123  0.960205  0.000054  0.005191  0.034551   \n",
       "124  0.000026  0.000025  0.999923  0.000026   \n",
       "125  0.000020  0.000020  0.999940  0.000020   \n",
       "126  0.000022  0.000022  0.967390  0.032566   \n",
       "\n",
       "                                             title author gender    year  \\\n",
       "0                            A Dog with a Bad Name          Male  1886.0   \n",
       "1                                A Final Reckoning          Male  1887.0   \n",
       "2    A House Party, Don Gesualdo, and A Rainy June        Female  1887.0   \n",
       "3                              A Houseful of Girls        Female  1889.0   \n",
       "4                            A Little Country Girl        Female  1885.0   \n",
       "..                                             ...           ...     ...   \n",
       "122                                Treasure Island          Male  1883.0   \n",
       "123                                   Twice Bought          Male  1885.0   \n",
       "124                                     Two Arrows          Male  1886.0   \n",
       "125             Uncle Remus: His Songs and Sayings          Male  1880.0   \n",
       "126                             Under Drake's Flag          Male  1883.0   \n",
       "\n",
       "                                                  text  word_count  \\\n",
       "0    A DOG WITH A BAD NAME  BY TALBOT BAINES REED  ...       96493   \n",
       "1    A Final Reckoning: A Tale of Bush Life in Aust...      100603   \n",
       "2    A HOUSE-PARTY  Don Gesualdo  and  A Rainy June...       85132   \n",
       "3    A HOUSEFUL OF GIRLS. BY SARAH TYTLER,  AUTHOR ...       92822   \n",
       "4    LITTLE COUNTRY GIRL.  BY  SUSAN COOLIDGE,     ...       48251   \n",
       "..                                                 ...         ...   \n",
       "122  TREASURE ISLAND  by Robert Louis Stevenson    ...       68589   \n",
       "123  The Project Gutenberg EBook of Twice Bought, b...       76593   \n",
       "124  TWO ARROWS      HARPER'S YOUNG PEOPLE'S SERIES...       56018   \n",
       "125  Uncle Remus: His Songs and His Sayings  By Joe...       53942   \n",
       "126  Under Drake's Flag:  A Tale of the Spanish Mai...      108275   \n",
       "\n",
       "             0_wc         1_wc           2_wc          3_wc  \n",
       "0    89544.893129  1386.608095    5558.264002      3.234773  \n",
       "1     2750.319905  7055.421499   49429.084933  41368.173663  \n",
       "2    82773.973483     3.116905    1923.824216    431.085396  \n",
       "3    92813.400143     2.846490       2.882587      2.870780  \n",
       "4    46769.319262  1393.626070       2.921490     85.133178  \n",
       "..            ...          ...            ...           ...  \n",
       "122      3.232002     3.214454       3.282020  68579.271523  \n",
       "123  73544.948175     4.102616     397.586668   2646.362541  \n",
       "124      1.447412     1.423235   56013.692946      1.436407  \n",
       "125      1.081305     1.091519   53938.737610      1.089566  \n",
       "126      2.422885     2.422565  104744.124318   3526.030232  \n",
       "\n",
       "[127 rows x 13 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a for loop to do this for every topic\n",
    "\n",
    "col_list = []\n",
    "for num in topic_columns:\n",
    "    col = \"%d_wc\" % num\n",
    "    col_list.append(col)\n",
    "    df_w_topics[col] = df_w_topics[num] * df_w_topics['word_count']\n",
    "    \n",
    "df_w_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "- What is the total number of words aligned with each topic, by author gender?\n",
    "- What is the proportion of total words aligned with each topic, by author gender?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_wc\n",
      "author gender\n",
      "Female    1.150752e+06\n",
      "Male      2.460418e+06\n",
      "Name: 0_wc, dtype: float64\n",
      "1_wc\n",
      "author gender\n",
      "Female    1.484812e+05\n",
      "Male      1.719037e+06\n",
      "Name: 1_wc, dtype: float64\n",
      "2_wc\n",
      "author gender\n",
      "Female    1.392767e+05\n",
      "Male      2.593460e+06\n",
      "Name: 2_wc, dtype: float64\n",
      "3_wc\n",
      "author gender\n",
      "Female    6.686701e+04\n",
      "Male      1.124740e+06\n",
      "Name: 3_wc, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#solution\n",
    "grouped = df_w_topics.groupby('author gender')\n",
    "for e in col_list:\n",
    "    print(e)\n",
    "    print(grouped[e].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_wc\n",
      "author gender\n",
      "Female    0.764428\n",
      "Male      0.311538\n",
      "dtype: float64\n",
      "1_wc\n",
      "author gender\n",
      "Female    0.098634\n",
      "Male      0.217664\n",
      "dtype: float64\n",
      "2_wc\n",
      "author gender\n",
      "Female    0.092519\n",
      "Male      0.328384\n",
      "dtype: float64\n",
      "3_wc\n",
      "author gender\n",
      "Female    0.044419\n",
      "Male      0.142414\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for e in col_list:\n",
    "    print(e)\n",
    "    print(grouped[e].sum()/grouped['word_count'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author gender\n",
      "Female    0.764428\n",
      "Male      0.311538\n",
      "dtype: float64\n",
      "author gender\n",
      "Female    0.098634\n",
      "Male      0.217664\n",
      "dtype: float64\n",
      "author gender\n",
      "Female    0.092519\n",
      "Male      0.328384\n",
      "dtype: float64\n",
      "author gender\n",
      "Female    0.044419\n",
      "Male      0.142414\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for e in col_list:\n",
    "    print(grouped[e].sum()/grouped['word_count'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa8AAAEYCAYAAADrpHnMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAdSElEQVR4nO3dfbRcVZnn8e+PBBLsCAoJLy2BCxjEAIoS3kTg0uiIAgEbWEBwWkbozNjS4mLotWK32owMbdAe7aVCt1mCAbs7vA3EIG+NYBIxoEkwCAkEQiAQlBbCa0ASEp754+wbKpmbe6sqt+rUrvP7rHVXzjm1z6mnkif3qb3Py1ZEYGZmlpOtyg7AzMysUS5eZmaWHRcvMzPLjouXmZllx8XLzMyy4+JlZmbZcfEyM7PsuHiZmVl2XLwaIGkHSTdJek3SCkmTyo7JOp+k8yQtkLRG0vSy47E8SBoh6Yr0u+ZVSYskfbLsuDrF8LIDyMxlwFpgZ+BA4BZJD0TE4lKjsk73O+B/A58Ati05FsvHcOBp4GjgKeBTwHWSDoiIJ8sMrBO451UnSX8CnAJ8NSJWR8Q9wCzgvw6wzwpJB6XlsySFpP3S+jmSZqblYZL+VtLj6RvWQkljW/6hrC0i4saImAmsqqe9pDmSTknLR6S8OT6tHytpUU3bv5T0cMqbJZI+3IKPYCWIiNci4qKIeDIi3oqInwJPAAdtbp8q5Y6LV/32AdZFxKM12x4A9htgnzlAb1o+GlgOHFWzPictXwCcSfHNajvgc8DrQxK15aiuvJF0GnAR8BcUeTOROguk5UfSzhS/hwYa6alM7rh41W8U8Mom214G3jnAPnMoEgbgSOAbNeu1xetc4CsRsTQKD0REVolkQ6o2b45i4Lz5ZkTMT3mzLCJWtDdUawdJWwP/BlwVEY8M0LQyuePiVb/VFN9Qam0HvDrAPnOAIyXtCgwDrgOOkNQDbA8sSu3GAo8PZbCWtXuBfdI37QOBq4GxkkYDhwBzUzvnTQVI2gr4McX59vMGaV6Z3HHxqt+jwHBJ42q2fZABuvARsYxi+O+vgbkR8QrwLDAZuCci3kpNnwb2bknUlp2IeB1YCJwPPBQRa4F5FMPLj0fE86mp86bLSRJwBcVFYqdExJsDta9S7rh41SkiXgNuBL4u6U8kHQGcRPGNaCBzKL4t9XXXZ2+yDvBD4GJJ41T4gKQdh/QDWGkkDZc0kqL3PUzSSEmDXelbb95cKOmglDfvlbTHEIdv5fpn4P3AiRHxxzr3qUTuuHg15q8oLnX+AzAD+Hwdl8nPoTgvNncz6wDfphhS/A+K82pX4Euqu8lXgD8CU4DPpOWvDLLPoHkTEdcDlwD/TjF8PRPYYQjjthKlYvLfKYb/npW0Ov2cNciulcgdeSZlMzPLjXteZmaWHRevLSTpX2q687U//1J2bNa50k3p/eXNbWXHZp3NuVPwsKGZmWWn455tOHr06Ojp6Sk7DOvHwoULn4+IMWXHsTnOnc7kvLFmDZQ7LS9ekq4ETgD+EBH7D9a+p6eHBQsWtDosa4Kkjr4D37nTmZw31qyBcqcd57ymA8e14X3MzKwiWl68ImIu8EKr38fMzKqjklcb9vb20tvbW3YYZqXy/wNrRqfkTUcUL0mT00yzC5577rmywzEzsw7XEcUrIqZFxISImDBmTMdelGRmZh2iI4qXmZlZI1pevCTNoJhj5n2SVko6p9XvaWZm3a0dVxueGRG7RsTWEbFbRFzR6ve0zifpOElLJS2TNKWf18+W9JykRenn3DLiNLPO1HFP2LDuJ2kYcBnwcWAlMF/SrIhYsknTayNisJljzayCfM7LynAIsCwilqeZXq+hmNjTzKwuLl6Z65R7Lhr0HoppyPusTNs2dYqk30q6QdLY/g7k2yzMqsnFyzrVzUBPRHwAuBO4qr9Gvs3CrJpcvKwMzwC1Pand0rYNImJVRKxJqz8EDmpTbGaWARcvK8N8YJykPSVtA5wBzKptIGnXmtWJwMNtjM/MOlxXXG3YM+WWhto/u3xVU/s9OfX4htpb/yJinaTzgDuAYcCVEbFY0teBBRExC/iipInAOooHO59dWsBm1nG6onhZfiLiVuDWTbZ9rWb5y8CX2x2XmeXBw4ZmZpYdFy8zM8uOi5eZmWXHxcvMzLLj4mVmZtlx8TKzbHg2AuvjS+XNLAuejcBquedlZrnwbAS2gYuXmeViyGYjsPy5eJlZN6lrNgJPpZM/Fy8zy8WQzUbgqXTyV8kLNnaZNLXsEMyscRtmI6AoWmcAk2obSNo1In6fVj0bQRerZPEys/x4NgKr5eJlZtnwbATWx+e8zMwsOy5eZmaWHRcvMzPLjouXmZllxxdsmHWJnim3NNT+2eWrmtrvyanHN9TeOl8jOdApeeOel5mZZcfFy8zMsuNhww7joR8zs8G552VmZtlx8TIzs+y4eJmZWXZcvMzMLDsuXmYN6O3tpbe3t+wwzCrPxcvMzLLj4mVmZtnxfV5Wae24r8731JkNPfe8zMxazOdKh557XmYN2GXS1LJDMDNcvMzMGubHuJXPw4ZmZpadthQvScdJWippmaQp7XhP62yD5YSkEZKuTa//SlJPCWFah8k1b3aZNNVDzkOs5cVL0jDgMuCTwHjgTEnjW/2+1rnqzIlzgBcj4r3Ad4BL2xuldRrnjdVqR8/rEGBZRCyPiLXANcBJbXhf61z15MRJwFVp+QbgWElqY4zWeZw3tkE7Lth4D/B0zfpK4NDaBpImA5PT6mpJS9sQ12jg+UZ2UOd+hxu94tIT2vFZ9mhqr//foDlR2yYi1kl6GdiRTf7NcsidDs4baE/uOG8K/p3TuM3mTkdcbRgR04Bp7XxPSQsiYkI737NVuumzNMq5s2W66bM0wnmzZTrhs7Rj2PAZYGzN+m5pm1VXPTmxoY2k4cD2wKq2RGedynljG7SjeM0HxknaU9I2wBnArDa8r3WuenJiFvDZtHwqcHdERBtjtM7jvLENWj5smMadzwPuAIYBV0bE4la/bx3aOmTQYll9ls3lhKSvAwsiYhZwBfBjScuAFyh+UXWKrP6+B5HNZ3HedJTSP4v8pcTMzHLjJ2yYmVl2XLzMzCw7Ll5mZpYdFy8zM8tOpYqXCp+R9LW0vrukQ8qOq1mStpX0vrLjqALnjjXDedM6lSpewOXA4cCZaf1Vigd9ZkfSicAi4Pa0fqAk3z/XOs4da4bzpkWqVrwOjYgvAG8ARMSLwDblhtS0iygeVPoSQEQsAvYsL5yu59yxZjhvWqRqxevNNK1CAEgaA7xVbkhNezMiXt5km2/aax3njjXDedMiVSte3wVuAnaSdAlwD/AP5YbUtMWSJgHDJI2T9D1gXtlBdTHnjjXDedMilXvChqR9gWMBAXdFxMMlh9QUSe8A/g74LxSf5Q7g4oh4o9TAuphzx5rhvGlRPFUoXpJ2GOj1iHihXbFYXpw71gznTetVpXg9QTE2Wzujat96RMRepQTWBEk3M8A4c0RMbGM4Xc+5Y81w3rReJYpXN5F09ECvR8ScdsVieXHuWDM6NW8qV7wkvRsYB4zs2xYRc8uLyHLh3LFmOG9ao+XzeXUSSecC51PMwLoIOAy4F/izEsNqiqRxwDeA8Wz8nyKb4YicOHesGc6b1qnapfLnAwcDKyLiGOBDpBvuMvQj4J+BdcAxwNXAv5YaUXdz7lgznDctUrXi9UbfZZ2SRkTEI0BHPKerCdtGxF0UQ78rIuIi4PiSY+pmzh1rhvOmRSo1bAislPQuYCZwp6QXgRWlRtS8NZK2Ah5LU6M/A4wqOaZu5tyxZjhvWqRyF2z0SVfQbA/cHhFry46nUZIOBh4G3gVcTPFZvhkR95UZVxU4d6wZzpshjqdqxStd+TOWml5nRNxfXkSWC+eONcN50xqVGjaUdDFwNrCctx+OGWR05c9gUxD4RtPWcO5YM5w3rVOpnpekpcABOXbZ+0h6DngamAH8io3v4PeNpi3i3LFmOG9ap1I9L+AhivHaP5Qcx5bYBfg4xeR2k4BbgBkRsbjUqLqfc8ea4bxpkar1vCYAP6FIqDV923MdLpE0giKhvgX8r4j4fskhdS3njjXDedM6Vet5XQVcCjxIvhPC9SXQ8RRJ1MPbcwZZ6zh3rBnOm1bFVLGe1/yIOLjsOLaEpKuB/YFbgWsi4qGSQ6oE5441w3nTOlUrXt+m6LrPYuMufDaXrUp6C3gtrdb+4/VNtbBd+6Pqfs4da4bzpnWqVrx+3s/miIhsLlu1cjh3rBnOm9apVPEyM7PuUKkH80raWdIVkm5L6+MlnVN2XNb5nDvWDOdN61SqeAHTgTuAP03rjwJfKisYy8p0nDvWuOk4b1qiasVrdERcR7pkNSLWAevLDcky4dyxZjhvWqRqxes1STuSrpiRdBjwcrkhWSacO9YM502LVO0m5QsoLlndW9IvgTHAqeWGZJlw7lgznDctUomrDSXtHhFPpeXhFDOZClgaEW+WGpx1NOeONcN503pVGTacWbN8bUQsjoiHnERWh5k1y84dq9fMmmXnTQtUpXjVPsJ/r9KisBw5d6wZzpsWq0rxis0smw3GuWPNcN60WFXOea2neDaXgG2B1/tews90swE4d6wZzpvWq0TxMjOz7lKVYUMzM+siLl5mZpYdFy9A0smSxtesz07Td3c0SdMl+YbHkjhvrFnOnS3n4lU4GRg/WKN6pBsSO1Inx5apk3HeWHNOxrmzRbqyeEmaKWmhpMWSJtdsX12zfGr6FvERYCLwLUmLJO2dmpwm6deSHpV0ZNpnpKQfSXpQ0m8kHZO2ny1plqS7gbv6ieerkpZKukfSDEkXpu17S7o9xfoLSfum7dMlfVfSPEnL+77pqPD9dKyfATvVvMdBkuakY90hade0fbakf5K0ADh/KP+eu43zxnnTLOdOCbkTEV33A+yQ/twWeAjYMa2vrmlzKjA9LU8HTq15bTbwf9Lyp4CfpeX/CVyZlvcFngJGAmcDK/ved5NYDgYWpXbvBB4DLkyv3QWMS8uHAnfXxHM9xZeL8cCytP3PgTuBYRRTLLyUPsfWwDxgTGp3ek2cs4HLy/43yeHHeeO8ce7kkzsd293cQl+U9Om0PBYYB6xq8Bg3pj8XAj1p+aPA9wAi4hFJK4B90mt3RsQL/RznCOAnEfEG8IakmwEkjQI+AlwvbbgZf0TNfjMj4i1giaSd07ajgBkRsR74XfrWBcVz0/YH7kzHGgb8vuZY1zbywSvMeeO8aZZzp82503XFS1Iv8DHg8Ih4XdJsim8gsPGd7iMZ2Jr053rq+3t6rf4ogeIbzksRceAg7w8bP2qmPwIWR8ThQxRb5ThvhiS2SnLuDElsDevGc17bAy+mJNoXOKzmtf+U9H5JWwGfrtn+KkX3ejC/AM4CkLQPsDuwdJB9fgmcmMauRwEnAETEK8ATkk5Lx5OkDw5yrLnA6ZKGpfHlY9L2pcAYSYenY20tab86Po+9zXnjvGmWc6eE3OnG4nU7MFzSw8BU4L6a16YAP6UYq63t4l4D/E06Ibo3m3c5sJWkBym6xWdHxJoB2hMR8ynm8/ktcBvwIG9PRncWcI6kB4DFwEmDfLabKMavlwBXA/em91hLMQ59aTrWIorhAauf88Z50yznTgm548dDtYGkURGxWtI7KL7JTI6I+8uOyzqb88aaVYXc6bpzXh1qmoobEkcCV3VbElnLOG+sWV2fO+55mZlZdrrxnJeZmXU5Fy8zM8uOi5eZmWXHxcvMzLLj4mVmZtlx8TIzs+y4eJmZWXZcvMzMLDsuXmZmlh0XLzMzy46Ll5mZZcfFy8zMsuPi1QBJ/yrp95JekfSopHPLjsnMrIr8VPkGpJlCl0XEmjRj6mzg+IhYWG5kZmbV4p5XAyJicc0sppF+NjsLqqQ5kk5Jy0dICknHp/VjJS2qafuXkh6W9KqkJZI+3LpPYmaWNxevBkm6XNLrwCMU03rfOkDzOUBvWj4aWA4cVbM+Jx3zNOAi4C+A7YCJwKohDt3MrGu4eDUoIv4KeCdwJHAjsGaA5nMoihQUResbNesbihdwLvDNiJgfhWURsWLIgzcz6xIuXk2IiPURcQ+wG/D5AZreC+wjaWfgQOBqYKyk0cAhwNzUbizweOsiNjPrLi5eW2Y4A5zziojXgYXA+cBDEbEWmAdcADweEc+npk8PdBwzM9uYi1edJO0k6QxJoyQNk/QJ4EzgrkF2nQOcx9tDhLM3WQf4IXChpINUeK+kPYb4I5iZdQ0Xr/oFxRDhSuBF4B+BL0XErEH2m0NxjmzuZtaJiOuBS4B/B14FZgI7DGHsZmZdxfd5mZlZdtzzMjOz7Lh4bSFJfytpdT8/t5Udm5lZt/KwoZmZZWd42QFsavTo0dHT01N2GNaPhQsXPh8RY8qOw8ys44pXT08PCxYsKDsM64ckP/XDzDqCz3mZmVl2XLwy19vbS29vb9lhmJm1lYuXmZllx8XLzMyy4+JlZmbZcfEyM7PsuHiZmVl2XLzMzCw7Ll5mZpYdFy8zM8uOi5eZmWXHxcvMzLLj4mVmZtlx8TIzs+y4eJmZWXZcvMzMLDsuXmZmlp26ipek4yQtlbRM0pR+Xr9A0hJJv5V0l6Q9al5bL2lR+pk1lMGbmVk1DR+sgaRhwGXAx4GVwHxJsyJiSU2z3wATIuJ1SZ8Hvgmcnl77Y0QcOLRhm5lZldXT8zoEWBYRyyNiLXANcFJtg4j4eUS8nlbvA3Yb2jDNzMzeVk/xeg/wdM36yrRtc84BbqtZHylpgaT7JJ3c3w6SJqc2C5577rk6QjIzsyobdNiwEZI+A0wAjq7ZvEdEPCNpL+BuSQ9GxOO1+0XENGAawIQJE2IoYzIzs+5TT8/rGWBszfpuadtGJH0M+DtgYkSs6dseEc+kP5cDs4EPbUG8ZmZmdRWv+cA4SXtK2gY4A9joqkFJHwJ+QFG4/lCz/d2SRqTl0cARQO2FHmZmZg0bdNgwItZJOg+4AxgGXBkRiyV9HVgQEbOAbwGjgOslATwVEROB9wM/kPQWRaGcuslVimZmZg2r65xXRNwK3LrJtq/VLH9sM/vNAw7YkgDNzMw25SdsmJlZdly8zMwsOy5eZmaWHRcvMzPLjouXmZllx8XLzMyy4+JlZmbZcfEyM7PsDOmDeW3L9Uy5paH2zy5f1dR+T049vqH2ZmadxD0vMzPLjouXmZllx8XLzMyy4+JlZmbZcfEyM7PsuHiZmVl2XLzMzCw7Ll5mZpYdFy8zM8uOi5eZmWWnksWrt7eX3t7essMwM7MmVbJ4mZlZ3rriwbx+mK2ZWbW452VmZtmpq3hJOk7SUknLJE3p5/URkq5Nr/9KUk/Na19O25dK+sQQxt60XSZNZZdJU8sOw8zMmjRo8ZI0DLgM+CQwHjhT0vhNmp0DvBgR7wW+A1ya9h0PnAHsBxwHXJ6OZ2Zm1rR6el6HAMsiYnlErAWuAU7apM1JwFVp+QbgWElK26+JiDUR8QSwLB3PzMysafUUr/cAT9esr0zb+m0TEeuAl4Ed69zXzMysIR1xtaGkycDktLpa0tI2vO1o4PlGdtClLYpky41ecekJ7fgsezS1l5nZEKuneD0DjK1Z3y1t66/NSknDge2BVXXuS0RMA6bVH/aWk7QgIia08z1bpZs+i5lZPeoZNpwPjJO0p6RtKC7AmLVJm1nAZ9PyqcDdERFp+xnpasQ9gXHAr4cmdDMzq6pBe14RsU7SecAdwDDgyohYLOnrwIKImAVcAfxY0jLgBYoCR2p3HbAEWAd8ISLWt+izmJlZRajoIFWPpMlpuDJ73fRZzMzqUdniZWZm+fLjoczMLDsuXmZmlh0XLzMzy46LV8YkbSvpfWXHYWbWbpUqXip8RtLX0vrukrJ81qKkE4FFwO1p/UBJm95/Z2bWlSpVvIDLgcOBM9P6qxRPzM/RRRQPOX4JICIWAXuWF46ZWft0xLMN2+jQiPiwpN8ARMSL6akhOXozIl4uHt6/ge97MLNKqFrxejPNJxYAksYAb5UbUtMWS5oEDJM0DvgiMK/kmMzM2qJqw4bfBW4CdpJ0CXAP8A/lhtS0v6aY5HMNMAN4BfhSmQGZmbVL5Z6wIWlf4FhAwF0R8XDJIZmZWYMqUbwk7TDQ6xHxQrti2VKSbmaAc1sRMbGN4ZiZlaIq57wWUvzCr726oW89gL3KCKpJ/1h2AGZmZatEz8vMzLpLVXpeG0h6N8WkmCP7tkXE3PIiak66wvAbwHg2/iw59SLNzJpSqeIl6VzgfGA3iqdTHAbcC/xZiWE160fA3wPfAY4B/hvVu3rUzCqqar/szgcOBlZExDHAh0hPqMjQthFxF8XQ74qIuAg4vuSYzMzaolI9L+CNiHhDEpJGRMQjGT/Ydo2krYDHJJ0HPAOMKjkmM7O2qFrxWinpXcBM4E5JLwIrSo2oeecD76B4ssbFFEOfny01IjOzNqns1YaSjga2B26PiLVlx2NmZvWrXPFKVxuOpabXGRH3lxdRYwab9sQ3KZtZFVRq2FDSxcDZwHLefiBvkNfVhocDT1M8z/BXbHzjtZlZJVSq5yVpKXBAzsOE6an4H6eYk+wDwC3AjIhYXGpgZmZtVLVL5R8C3lV2EFsiItZHxO0R8VmK+9SWAbPTFYdmZpVQtZ7XBOAnFEVsTd/23M4TSRpBcU/XmUAPMAu4MiKeKTMuM7N2qVrxWgz8AHiQmkkoI2JOaUE1SNLVwP7ArcA1EfFQySGZmbVd1YrX/Ig4uOw4toSkt4DX0mrtP56AiIjt2h+VmVl7Va14fZtiuHAWGw8bZnOpvJmZVa94/byfzREROV0qb2ZWeZUqXmZm1h0qdam8pJ0lXSHptrQ+XtI5ZcdlZmaNqVTxAqYDdwB/mtYfBb5UVjBmZtacqhWv0RFxHeky+YhYB6wvNyQzM2tU1YrXa5J2JF1iLukw4OVyQzIzs0ZV6sG8wAUUl8nvLemXwBjg1HJDMjOzRlXiakNJu0fEU2l5OPA+ipt6l0bEm6UGZ2ZmDavKsOHMmuVrI2JxRDzkwmVmlqeqFK/aOa/2Ki0KMzMbElUpXrGZZTMzy1BVznmtp3iYrYBtgdf7XsIPszUzy04lipeZmXWXqgwbmplZF3HxMjOz7Lh4AZJOljS+Zn22pAllxlQPSdMl+SZrM6scF6/CycD4wRrVI90E3ZE6OTYzs0Z0ZfGSNFPSQkmLJU2u2b66ZvnU1HP5CDAR+JakRZL2Tk1Ok/RrSY9KOjLtM1LSjyQ9KOk3ko5J28+WNEvS3cBd/cTzVUlLJd0jaYakC9P2vSXdnmL9haR90/bpkr4raZ6k5X29KxW+n471M2Cnmvc4SNKcdKw7JO2ats+W9E+SFgDnD+Xfs5lZWbr1m/jnIuIFSdsC8yX934hY1V/DiJgnaRbw04i4AUASwPCIOETSp4C/Bz4GfKHYJQ5IheY/JO2TDvVh4AMR8ULt8SUdDJwCfBDYGrgfWJhengb8j4h4TNKhwOVA36zOuwIfBfaleB7jDcCnKR5tNR7YGVgCXClpa+B7wEkR8Zyk04FLgM+lY20TER0/DGpmVq9uLV5flPTptDwWGAf0W7wGcGP6cyHQk5Y/SlEkiIhHJK0A+orXnZsWruQI4CcR8QbwhqSbASSNAj4CXJ+KJcCImv1mRsRbwBJJO6dtRwEzImI98LvU04OioO0P3JmONQz4fc2xrm3kg5uZdbquK16Seil6SYdHxOuSZgMj08u1N7WNZGBr0p/rqe/v6bX6owSKIduXIuLAQd4fNn68VX8ELI6Iw4coNjOzjtaN57y2B15MhWtf4LCa1/5T0vslbUUxBNfnVeCddRz7F8BZAGm4cHdg6SD7/BI4MZ0vGwWcABARrwBPSDotHU+SPjjIseYCp0sals5pHZO2LwXGSDo8HWtrSfvV8XnMzLLUjcXrdmC4pIeBqcB9Na9NAX4KzGPjYbVrgL9JF2HszeZdDmwl6UGKobizI2LNAO2JiPkU56x+C9wGPMjbE2CeBZwj6QFgMXDSIJ/tJuAxinNdVwP3pvdYSzEv2aXpWIsohiTNzLqSHw/VBpJGRcRqSe+g6D1Njoj7y47LzCxXXXfOq0NNSzdBjwSucuEyM9sy7nmZmVl2uvGcl5mZdTkXLzMzy46Ll5mZZcfFy8zMsuPiZWZm2fl/pBHQEz6kJR4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig2 = plt.figure()\n",
    "chrt = 0\n",
    "for e in col_list:\n",
    "    chrt += 1 \n",
    "    ax2 = fig2.add_subplot(2,3, chrt)\n",
    "    (grouped[e].sum()/grouped['word_count'].sum()).plot(\n",
    "        kind = 'bar', \n",
    "        yerr = grouped[e].sum()/grouped['word_count'].sum().std(), \n",
    "        ylim=0, ax=ax2, title=e)\n",
    "\n",
    "fig2.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Why might we want to do one calculation over the other? Take average topic weight per documents versus the average number of words aligned with each topic?\n",
    "\n",
    "This brings us to...\n",
    "\n",
    "## Topic Prevalence <a id='prevalence'></a>\n",
    "\n",
    "How do we define prevalence? What are different ways of measuring this, and the benefits/drawbacks of each?\n",
    "\n",
    "#### TO DO: Provide some answers here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "- Find the most prevalent topic in the corpus.\n",
    "- Find the least prevalent topic in the corpus.        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_wc\n",
      "0.3840432895308944\n",
      "1_wc\n",
      "0.19860793419265882\n",
      "2_wc\n",
      "0.29062288331375674\n",
      "3_wc\n",
      "0.12672589296269\n"
     ]
    }
   ],
   "source": [
    "#solution\n",
    "for e in col_list:\n",
    "    print(e)\n",
    "    print(df_w_topics[e].sum()/df_w_topics['word_count'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prevalence over time <a id='overtime'></a>\n",
    "\n",
    "We can do the same as above, but by year, to graph the prevalence of each topic over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grouped_year = df_w_topics.groupby('year')\n",
    "fig3 = plt.figure()\n",
    "chrt = 0\n",
    "for e in col_list:\n",
    "    chrt += 1 \n",
    "    ax2 = fig3.add_subplot(2,3, chrt)\n",
    "    (grouped_year[e].sum()/grouped_year['word_count'].sum()).plot(\n",
    "        kind='line', title=e)\n",
    "    \n",
    "fig3.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic 2 I interpret to be about battles in France. What is going on between 1800 and 1804 in France that might make this topic increasingly popular over this time period?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA as dimensionality reduction <a id='dimensionality'></a>\n",
    "\n",
    "Another use for topic modeling is to reduce the dimensionality of text. Instead of representing a document as a vector of token counts over the whole vocabulary (which may be very large), topic modeling can represent that document as a weighted average of _k_ topics over a finite number of (more or less) interpretable topics. The latter approach is usually more tractable for subsequent statistical analysis (linear regression, decision trees, transformers, etc). \n",
    "\n",
    "Now that we obtained a distribution of topic weights for each document, we can represent our corpus with a dense document-weight matrix as opposed to our initial sparse DTM. The weights can then replace tokens as features for any subsequent task (classification, prediction, etc). A simple example may consist in measuring cosine similarity between documents. For instance, which book is closest to the first book in our corpus? Let's use pairwise cosine similarity to find out. \n",
    "\n",
    "NB: cosine similarity measures an angle between two vectors, which provides a measure of distance robust to vectors of different lenghts (total number of tokens)\n",
    "\n",
    "First, let's turn the DTM into a long-format, readable dataframe (remember: this is memory-inefficient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = tf_vectorizer.fit_transform(df_lit['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's import the cosine_similarity function from sklearn and print the cosine similarity between the first and second book or the first and third book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between first and second book:  [[0.28012828]]\n",
      "Cosine similarity between first and third book:  [[0.40808192]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(\"Cosine similarity between first and second book: \", \n",
    "      str(cosine_similarity(dtm[0,:], dtm[1,:])))\n",
    "print(\"Cosine similarity between first and third book: \", \n",
    "      str(cosine_similarity(dtm[0,:], dtm[2,:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we use the topic weights instead of word frequencies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'A Dog with a Bad Name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-dfc13253f838>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdwm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_w_topics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cosine similarity between first and second book: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdwm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdwm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cosine similarity between first and third book: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdwm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdwm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1249\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    154\u001b[0m         )\n\u001b[1;32m    155\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         X = check_array(\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'A Dog with a Bad Name'"
     ]
    }
   ],
   "source": [
    "dwm = df_w_topics.iloc[:,:10]\n",
    "\n",
    "print(\"Cosine similarity between first and second book: \" + str(cosine_similarity(dwm.iloc[0,:], dwm.iloc[1,:])))\n",
    "print(\"Cosine similarity between first and third book: \" + str(cosine_similarity(dwm.iloc[0,:], dwm.iloc[2,:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TO DO: Fix this code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Calculate the cosine similarity between the first book and all other books to identify the most similar one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TO DO: Add solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising topics with pyLDAvis <a id='viz'></a>\n",
    "\n",
    "Understanding the data that underlies a topic model is vital, but fortunately we also have a slightly more human-friendly option to help us interpret the topics!\n",
    "\n",
    "[pyLDAvis](https://github.com/bmabey/pyLDAvis) is a library for creating interactive topic model visualisations. It even has a helper function specifically for scikit-learn that we can use.\n",
    "\n",
    "> **It will take a while to load this visualisation!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.sklearn\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "# Silence an annoying warning we cannot do anything about\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el108401402717142992328554899208\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el108401402717142992328554899208_data = {\"mdsDat\": {\"x\": [0.06714350525623534, 0.012048293767481701, -0.099978848456322, 0.020787049432604936], \"y\": [-0.05770295428846498, 0.06313592414899487, -0.026718087826115167, 0.021285117965585302], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [35.72370154650118, 35.454139218819094, 17.201155184117454, 11.621004050562272]}, \"tinfo\": {\"Term\": [\"dick\", \"jack\", \"uncle\", \"er\", \"doctor\", \"king\", \"project\", \"ain\", \"den\", \"frank\", \"ye\", \"troops\", \"army\", \"yer\", \"fish\", \"tom\", \"deck\", \"french\", \"em\", \"wolf\", \"george\", \"prince\", \"ship\", \"camp\", \"shore\", \"rock\", \"officers\", \"attack\", \"mate\", \"gun\", \"troops\", \"column\", \"army\", \"slain\", \"nightfall\", \"assuredly\", \"spanish\", \"king\", \"arrows\", \"leaders\", \"defended\", \"council\", \"assailants\", \"division\", \"british\", \"prince\", \"french\", \"officers\", \"flank\", \"troop\", \"inhabitants\", \"marched\", \"guards\", \"resistance\", \"regiment\", \"majesty\", \"numbers\", \"erected\", \"guns\", \"ships\", \"daybreak\", \"attack\", \"camp\", \"soldiers\", \"prisoners\", \"rode\", \"march\", \"sword\", \"fort\", \"captured\", \"officer\", \"castle\", \"advanced\", \"count\", \"city\", \"france\", \"village\", \"native\", \"john\", \"ship\", \"wounded\", \"shore\", \"boats\", \"band\", \"indian\", \"tom\", \"james\", \"jack\", \"mamma\", \"darling\", \"_you_\", \"flower\", \"dearest\", \"vi\", \"term\", \"reader\", \"baby\", \"amiable\", \"papa\", \"silk\", \"rosy\", \"slender\", \"loving\", \"grace\", \"perplexed\", \"affectionate\", \"tenderly\", \"dreadfully\", \"kiss\", \"sofa\", \"murmured\", \"purse\", \"parcel\", \"fifth\", \"referred\", \"sympathetic\", \"shy\", \"awfully\", \"sweet\", \"charming\", \"sister\", \"project\", \"remarked\", \"dr\", \"loved\", \"aunt\", \"foundation\", \"girls\", \"sisters\", \"everybody\", \"christmas\", \"tea\", \"queer\", \"study\", \"youth\", \"nurse\", \"london\", \"street\", \"cousin\", \"doctor\", \"office\", \"works\", \"wasn\", \"public\", \"presently\", \"tom\", \"ladies\", \"em\", \"ain\", \"er\", \"dick\", \"excitedly\", \"den\", \"wolf\", \"uncle\", \"patch\", \"hook\", \"nay\", \"growth\", \"glided\", \"patches\", \"roared\", \"yer\", \"ejaculated\", \"hoarse\", \"fish\", \"staring\", \"thoughtfully\", \"dish\", \"rubbing\", \"panting\", \"beneath\", \"ain\", \"glow\", \"rub\", \"yonder\", \"dread\", \"growled\", \"shock\", \"sand\", \"doctor\", \"penny\", \"gun\", \"moments\", \"rock\", \"birds\", \"tom\", \"thrust\", \"pole\", \"rope\", \"em\", \"jack\", \"lads\", \"ay\", \"rocks\", \"eh\", \"ha\", \"tail\", \"stream\", \"mate\", \"garden\", \"lee\", \"cheese\", \"passengers\", \"coal\", \"frank\", \"hotel\", \"stomach\", \"illustration\", \"jack\", \"interposed\", \"steam\", \"afore\", \"ye\", \"liberal\", \"female\", \"union\", \"berth\", \"cabin\", \"reckon\", \"liable\", \"george\", \"fence\", \"minister\", \"shirt\", \"hired\", \"drunk\", \"thou\", \"fore\", \"card\", \"deck\", \"mate\", \"st\", \"ma\", \"lake\", \"headed\", \"sunday\", \"vessel\", \"bottle\", \"wheel\", \"church\", \"shore\", \"project\", \"ship\", \"uncle\", \"sail\", \"boats\", \"office\", \"works\", \"island\", \"em\", \"ain\", \"south\", \"john\", \"street\", \"officer\", \"doctor\", \"girls\"], \"Freq\": [4914.0, 3862.0, 3740.0, 2337.0, 5069.0, 4248.0, 2776.0, 2418.0, 1303.0, 1457.0, 1891.0, 2180.0, 2587.0, 1723.0, 1735.0, 3170.0, 1583.0, 2540.0, 1988.0, 860.0, 1112.0, 1922.0, 2691.0, 2521.0, 2019.0, 1464.0, 1941.0, 2235.0, 932.0, 1270.0, 2057.479606206412, 590.0318572382253, 2340.862709376204, 262.8743915745709, 207.74713677375578, 237.821093213187, 486.86493066731214, 3715.4604148226385, 683.7234470912601, 283.3386090006442, 189.30204126838711, 419.16865113346614, 283.31957361534415, 356.18852499307997, 817.6036164678361, 1633.422482065865, 2152.3933607521253, 1643.2763308793774, 208.9687061214517, 395.7202688050581, 368.0777618313191, 734.1495174315183, 276.7738367561517, 458.67134379651554, 972.1555473800702, 438.889208562807, 659.3780960480857, 180.26800244195957, 1225.4542855357909, 699.2741456548423, 319.46698270885383, 1820.541048415052, 1995.8443838950202, 1376.7741017330645, 700.4571989298236, 1081.3249885255204, 960.309038727627, 804.5136057769703, 828.6769824544582, 478.8486279318396, 1250.7432236639993, 775.2641607690359, 803.8128435096937, 570.2106862216164, 1315.006962618505, 661.0207925168822, 1282.0745704473986, 712.949697690846, 1433.9522597704222, 1612.7452089519772, 821.2360856988629, 1056.9988801266356, 817.570173956797, 739.3323440386239, 747.9530917957039, 891.546935791622, 754.7187873669134, 758.2501877168496, 1018.2431019543073, 574.903006611965, 293.90792146948485, 538.4359331683452, 212.19871060941958, 363.9791492068124, 390.19135921222875, 458.4859545942358, 898.6252558763949, 167.57974944207885, 1050.6638361498594, 390.36656083551685, 118.66986437240178, 112.36145978696347, 268.8137762824776, 318.37539608953495, 174.9470621591413, 182.8688201011936, 199.72844733763787, 159.3412030775027, 296.95951162485744, 177.65524990021652, 245.93399425931955, 360.2189920686737, 139.13834666670755, 301.48031418800326, 207.19792549958999, 144.0655838991348, 163.0228891039145, 266.46967888179546, 848.0890240420931, 257.49794004538626, 1100.4321549664405, 2063.3376322223935, 750.0200933191946, 769.0364167865649, 565.5105373586086, 748.171016702776, 635.3166522911494, 1534.1292607212383, 424.78612139943033, 550.7079753509645, 366.86320537856443, 717.6867657825354, 354.7255697395764, 611.6024309437248, 666.7473740862846, 489.3763714967536, 925.2874505666061, 797.4225198045659, 579.9282866262051, 1948.15022617106, 576.2047431686817, 781.7033644085914, 557.7553951061751, 541.5300418140836, 628.9973757492952, 834.4084930644382, 558.6916253106449, 602.9794520540206, 581.5482839555597, 2155.3625859148046, 4483.672785835032, 357.67771226462634, 1090.20213411732, 632.3543004453678, 2638.151118214765, 197.48570024395417, 300.4689609987303, 338.05701854051284, 119.35095840071789, 184.59773253167938, 100.70815641019006, 176.62659100666005, 1073.3095548991596, 113.6549959454576, 114.18643885337033, 1043.7162487152357, 223.3743039626078, 150.49264578547047, 166.4385115722676, 114.0283065275935, 160.17865566345844, 428.7096798353122, 1337.7021699310737, 142.377192806978, 80.72491272802512, 162.94103861199184, 174.11116417443594, 287.32198250156824, 411.21202973352797, 354.1941540874899, 2414.661974012157, 286.3798907312701, 630.3979434436372, 380.98114802500066, 705.3216429707526, 455.1189952013774, 1313.6427533343403, 349.75492849540115, 269.6678351782749, 615.2773763847698, 825.0517148349495, 1342.1117984227444, 605.6814349611299, 427.07543348586887, 437.7886623757193, 355.77915859331176, 474.40697616298, 390.69821002696267, 418.2273161028846, 360.3071608417529, 357.0373255462928, 135.75024034737444, 139.28020174983635, 242.21884126547602, 126.54068942332697, 702.9057578395281, 147.10347492841285, 75.16445979652046, 165.56412034398966, 1632.5938916967261, 76.43347079818004, 182.3325159274452, 90.09454580415908, 791.5454746933026, 57.774618623849115, 123.10448009510624, 96.08993605902724, 82.38916965251573, 323.2158295707712, 84.0358818798372, 60.390317518442544, 442.9430900438197, 72.52684209429464, 124.598122285403, 109.85790588120082, 60.2700089072634, 96.4187257454114, 227.7126958491639, 95.042609158797, 60.38056937558304, 571.0392874696194, 328.38177531967153, 296.1329292233248, 302.7624491813707, 325.9880985719691, 144.65058799970012, 148.70885643651715, 332.70680037414945, 165.43002575992267, 159.80321299621474, 235.27537999409267, 439.38353743291333, 551.2893124016155, 462.3129398796995, 524.3714463191142, 239.4823536568449, 282.2081698764176, 218.958736424422, 287.90439698770246, 274.10366161912833, 316.80004473138325, 329.6942196518816, 226.07754937113904, 290.1756807734756, 237.39110944695224, 257.1165845928589, 339.82949635367925, 245.323294382367], \"Total\": [4914.0, 3862.0, 3740.0, 2337.0, 5069.0, 4248.0, 2776.0, 2418.0, 1303.0, 1457.0, 1891.0, 2180.0, 2587.0, 1723.0, 1735.0, 3170.0, 1583.0, 2540.0, 1988.0, 860.0, 1112.0, 1922.0, 2691.0, 2521.0, 2019.0, 1464.0, 1941.0, 2235.0, 932.0, 1270.0, 2180.1634605854597, 651.3270996223825, 2587.402919731649, 291.8290490191948, 232.53418648973084, 270.3421465581181, 555.966204611138, 4248.552985839313, 785.0625079139913, 325.6518833469604, 217.58894439350314, 486.3132931310319, 330.1912865424196, 415.5552608843601, 953.9376553928399, 1922.4610384895727, 2540.88740285598, 1941.5540150563747, 247.41656539341182, 469.0205341172592, 436.8430095919698, 872.7897256976016, 329.07141085817017, 545.9230014363801, 1157.3429337661842, 523.3045749124994, 788.6057734330899, 215.67000087891557, 1466.6886985394874, 837.10805073833, 384.3069451264325, 2235.312109431039, 2521.019162871028, 1721.0705135950761, 860.0610743146804, 1358.6533596681197, 1215.3010865345832, 1007.769891783406, 1067.1693453274588, 582.3474499577691, 1703.200394588744, 999.1940484995173, 1053.2916884265783, 713.0915299441655, 1892.013362590353, 847.1434377048148, 1955.657149335198, 940.9337150394581, 2306.8690819926287, 2691.1028771331653, 1170.82169376733, 2019.0158133953246, 1420.2012418132927, 1064.7038992568125, 1202.444706403105, 3170.286363280861, 1375.326723373625, 3862.0443064693395, 1129.5039142651833, 654.122749637165, 340.08320782478177, 623.547779854116, 245.85558887217283, 428.3756992940531, 460.10408385173156, 544.9291165664371, 1090.1146020991464, 203.53204976418388, 1276.4607350435888, 476.62199836575576, 146.54909607786843, 138.81735298895703, 334.2957923650332, 396.42608483827837, 217.86317677820568, 228.2895739192038, 250.44053710726317, 200.97870772337583, 375.2786223071085, 226.00284867195506, 313.28949482129576, 460.19080557918136, 177.91361427107665, 386.41823790043367, 265.7997571439949, 185.1292800147073, 209.78673674753438, 343.6970879328556, 1103.758941910336, 332.1725997188738, 1446.6867987256771, 2776.34471395376, 1003.6387974760205, 1032.5258316460086, 749.7909198813983, 1006.8075750878348, 861.836436729968, 2264.5216834261696, 573.0572278258384, 764.2844538022347, 489.0880776063033, 1057.7006366956705, 475.19283668855303, 900.773114114106, 1017.0602386676597, 697.5836933986081, 1591.4407023165807, 1323.3218268145642, 917.2205753478272, 5069.883998128986, 924.3139168544952, 1552.3733898607197, 1000.7328571843873, 943.4477767566137, 1450.548112233687, 3170.286363280861, 1173.9040128692902, 1988.9960092242777, 2418.217380570171, 2337.1287958599246, 4914.600487821506, 413.8988558971955, 1303.5543014041364, 860.4166241317779, 3740.2315786725007, 280.725445637371, 430.45185705969357, 510.41053745444174, 181.3195399095297, 287.9107362095654, 157.45505138752438, 278.5196391718287, 1723.1999040494975, 183.4835001041481, 189.16497668193713, 1735.1499867107561, 376.9624770540426, 257.08332579484147, 287.8278748112482, 197.91284861682246, 279.234433274216, 773.1016574028007, 2418.217380570171, 258.9623906956312, 147.11331898634594, 298.6309615666268, 319.24239705584876, 528.7631100440454, 757.293665878436, 660.1062944224733, 5069.883998128986, 540.5211477622025, 1270.4852364982364, 744.321783464116, 1464.8235883865186, 916.2552578110058, 3170.286363280861, 693.949568777144, 510.4345412911286, 1366.622669948326, 1988.9960092242777, 3862.0443064693395, 1544.183125554432, 963.528025793692, 1013.884792646335, 757.3989070216315, 1255.405063243071, 902.502537904031, 1278.6850208006574, 932.2613363508248, 1104.8739448899455, 236.50634719283664, 258.51377990965966, 451.282222516816, 249.95155772754939, 1457.530007029321, 318.2840181143765, 164.692151258146, 384.4556979453595, 3862.0443064693395, 182.02354341620247, 434.419247855531, 215.1864880354471, 1891.704218374394, 138.60747257622316, 295.9621349351935, 233.04448090303947, 200.6175915134081, 790.2626294962297, 208.11237089954165, 151.21513198398952, 1112.0118764389147, 185.56273343905153, 321.57231054030086, 285.9643322518962, 159.2053002791685, 257.2039789868133, 613.5841163507346, 256.7088765743865, 164.54266000614658, 1583.2588825096755, 932.2613363508248, 857.331660917584, 901.9229535475951, 1103.6696166611698, 428.60922703665585, 449.45705170074586, 1266.4333805087433, 515.5059428604407, 493.7493159679559, 835.0149402179986, 2019.0158133953246, 2776.34471395376, 2691.1028771331653, 3740.2315786725007, 1052.188655626294, 1420.2012418132927, 924.3139168544952, 1552.3733898607197, 1439.3177406279408, 1988.9960092242777, 2418.217380570171, 1062.85766481309, 2306.8690819926287, 1323.3218268145642, 1703.200394588744, 5069.883998128986, 2264.5216834261696], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.077, -6.3261, -4.948, -7.1346, -7.3699, -7.2347, -6.5182, -4.486, -6.1787, -7.0596, -7.4629, -6.668, -7.0597, -6.8308, -5.9999, -5.3078, -5.0319, -5.3018, -7.364, -6.7255, -6.7979, -6.1075, -7.083, -6.5779, -5.8267, -6.622, -6.2149, -7.5118, -5.5952, -6.1562, -6.9396, -5.1993, -5.1074, -5.4787, -6.1545, -5.7203, -5.839, -6.016, -5.9864, -6.5348, -5.5747, -6.053, -6.0169, -6.3602, -5.5246, -6.2124, -5.55, -6.1368, -5.438, -5.3205, -5.9954, -5.743, -5.9999, -6.1005, -6.0889, -5.9133, -6.0799, -6.0752, -5.7728, -6.3445, -7.0154, -6.41, -7.3411, -6.8016, -6.732, -6.5707, -5.8978, -7.5772, -5.7415, -6.7316, -7.9223, -7.9769, -7.1046, -6.9354, -7.5342, -7.4899, -7.4017, -7.6276, -7.0051, -7.5188, -7.1936, -6.8119, -7.7632, -6.9899, -7.365, -7.7284, -7.6048, -7.1134, -5.9557, -7.1476, -5.6952, -5.0666, -6.0786, -6.0535, -6.3609, -6.081, -6.2445, -5.3629, -6.6471, -6.3874, -6.7937, -6.1226, -6.8273, -6.2826, -6.1962, -6.5055, -5.8685, -6.0173, -6.3357, -5.124, -6.3422, -6.0372, -6.3747, -6.4043, -6.2545, -5.9719, -6.3731, -6.2968, -6.333, -4.2997, -3.5672, -6.0958, -4.9813, -5.5259, -4.0976, -6.6897, -6.27, -6.1522, -7.1933, -6.7572, -7.3632, -6.8014, -4.9969, -7.2422, -7.2376, -5.0248, -6.5665, -6.9615, -6.8608, -7.2389, -6.8991, -5.9146, -4.7767, -7.0169, -7.5843, -6.882, -6.8157, -6.3148, -5.9563, -6.1055, -4.1861, -6.3181, -5.529, -6.0326, -5.4167, -5.8548, -4.7948, -6.1182, -6.3782, -5.5533, -5.2599, -4.7734, -5.569, -5.9184, -5.8937, -6.1011, -5.8133, -6.0075, -5.9394, -6.0884, -6.0975, -6.6724, -6.6467, -6.0934, -6.7427, -5.028, -6.5921, -7.2635, -6.4739, -4.1853, -7.2468, -6.3774, -7.0824, -4.9092, -7.5267, -6.7702, -7.0179, -7.1718, -5.8049, -7.152, -7.4824, -5.4898, -7.2993, -6.7581, -6.884, -7.4844, -7.0145, -6.1551, -7.0289, -7.4826, -5.2358, -5.7891, -5.8924, -5.8703, -5.7964, -6.6089, -6.5812, -5.776, -6.4747, -6.5093, -6.1225, -5.4979, -5.271, -5.447, -5.321, -6.1047, -5.9406, -6.1943, -5.9206, -5.9697, -5.825, -5.7851, -6.1623, -5.9127, -6.1135, -6.0337, -5.7548, -6.0807], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9714, 0.9305, 0.9292, 0.9249, 0.9166, 0.9012, 0.8966, 0.8953, 0.8911, 0.8902, 0.8901, 0.8808, 0.8763, 0.8752, 0.8751, 0.8664, 0.8634, 0.8626, 0.8605, 0.8594, 0.8581, 0.8564, 0.8563, 0.8552, 0.855, 0.8534, 0.8504, 0.8501, 0.8497, 0.8494, 0.8446, 0.8241, 0.7958, 0.8062, 0.8241, 0.801, 0.7939, 0.8041, 0.7764, 0.8337, 0.7206, 0.7756, 0.759, 0.8058, 0.6656, 0.7813, 0.6071, 0.7519, 0.5539, 0.5173, 0.6747, 0.3822, 0.4771, 0.6647, 0.5546, -0.2393, 0.4293, -0.5986, 0.9332, 0.9078, 0.891, 0.8902, 0.8897, 0.874, 0.8721, 0.8642, 0.8438, 0.8426, 0.8423, 0.8373, 0.8259, 0.8255, 0.8189, 0.8177, 0.8175, 0.8151, 0.8107, 0.8048, 0.8029, 0.7962, 0.7949, 0.792, 0.7911, 0.7887, 0.7879, 0.7861, 0.7847, 0.7824, 0.7734, 0.7823, 0.7634, 0.7401, 0.7456, 0.7423, 0.7549, 0.74, 0.732, 0.6475, 0.7375, 0.7092, 0.7494, 0.6491, 0.7446, 0.6498, 0.6147, 0.6824, 0.4946, 0.5304, 0.5785, 0.0805, 0.5643, 0.3509, 0.4524, 0.4818, 0.2014, -0.2979, 0.2944, -0.1566, -0.3882, 1.6792, 1.6684, 1.6142, 1.5815, 1.4522, 1.4111, 1.4085, 1.4007, 1.3482, 1.342, 1.3157, 1.3133, 1.3047, 1.2868, 1.2812, 1.2554, 1.2519, 1.2369, 1.2247, 1.2125, 1.2088, 1.2044, 1.1706, 1.1681, 1.162, 1.16, 1.1544, 1.1539, 1.1503, 1.1496, 1.1376, 1.0184, 1.125, 1.0594, 1.0905, 1.0294, 1.0605, 0.8792, 1.075, 1.1221, 0.9622, 0.8803, 0.7032, 0.8243, 0.9466, 0.9204, 1.0046, 0.787, 0.923, 0.6426, 0.8095, 0.6305, 1.5972, 1.5339, 1.5301, 1.4717, 1.4231, 1.3805, 1.368, 1.3099, 1.2913, 1.2846, 1.2842, 1.2817, 1.2811, 1.2773, 1.2752, 1.2664, 1.2624, 1.2583, 1.2455, 1.2345, 1.2319, 1.2129, 1.2042, 1.1957, 1.181, 1.1712, 1.1611, 1.1587, 1.1499, 1.1326, 1.1089, 1.0893, 1.0608, 0.9328, 1.0661, 1.0463, 0.8157, 1.0158, 1.0243, 0.8857, 0.6274, 0.5357, 0.3909, 0.1877, 0.6722, 0.5364, 0.7122, 0.4674, 0.4939, 0.3152, 0.1597, 0.6045, 0.0792, 0.4342, 0.2616, -0.5503, -0.0702]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4], \"Freq\": [0.0499877665490581, 0.8644943156131224, 0.02058319799078863, 0.06469005082819283, 0.7633213181440996, 0.13861307518537133, 0.059812491347112286, 0.03892558960685085, 0.07446682609349753, 0.8016134808888264, 0.05694521995385106, 0.0657060230236743, 0.09294263865073839, 0.27418078401967827, 0.2184152008292352, 0.41824187392832274, 0.06988619028126947, 0.2406731523295789, 0.5533001337061453, 0.1364641585373901, 0.05404554227574876, 0.8254228274841628, 0.06878523562368023, 0.05404554227574876, 0.9047682454663054, 0.04019474477936598, 0.016232493083974724, 0.0390352809876535, 0.8712682023466807, 0.015285407058713696, 0.09426001019540113, 0.01910675882339212, 0.8570789464598516, 0.03937111768190131, 0.03634257016790891, 0.06662804530783299, 0.8803658735055387, 0.07398032550466711, 0.014796065100933424, 0.03329114647710021, 0.8146513376440773, 0.04294702274235663, 0.10334127347379564, 0.03936810418049357, 0.0794590763711931, 0.7429423640706555, 0.14699929128670725, 0.030790392093837327, 0.06400985278146408, 0.7739373109031565, 0.06400985278146408, 0.09601477917219611, 0.13388297646426855, 0.2272897042300373, 0.4431630306220362, 0.1951162757773836, 0.034858720291267034, 0.8246839353118174, 0.05779208890394271, 0.08347746175013947, 0.6940896905851841, 0.15966880568265399, 0.06856366361666906, 0.077955946303884, 0.28844848263442896, 0.12676211344472663, 0.5549076190590584, 0.02975029193090523, 0.2243073484260849, 0.27415342585410374, 0.08972293937043396, 0.4087378349097547, 0.24556475728994978, 0.21827978425773314, 0.4965865091863429, 0.039290361166391966, 0.5759747111300856, 0.11195596463286504, 0.11406834132405116, 0.1985634089714965, 0.13966861293680966, 0.36663010895912534, 0.1726459243246675, 0.3200739046468555, 0.857498386163549, 0.07233177096000597, 0.041931461426090416, 0.02935202299826329, 0.29230788775530997, 0.12021320059201059, 0.1784216977207736, 0.40872488201283597, 0.7917432875547374, 0.04601313695207893, 0.09321626882533232, 0.0690197054281184, 0.8225330084895819, 0.06010157682074189, 0.046364073547429455, 0.07212189218489026, 0.0546970615381069, 0.546970615381069, 0.030387256410059387, 0.36464707692071263, 0.7756251162262346, 0.12510082519777976, 0.07105726871233892, 0.02702177824272043, 0.1414927060202356, 0.7736941584510754, 0.024083864854508183, 0.06020966213627046, 0.07349704919652542, 0.2166228818423907, 0.17020369287616413, 0.5376889388587912, 0.07360637408335803, 0.7503760913497888, 0.04293705154862552, 0.13290039765050754, 0.2766417567806541, 0.4011904265000828, 0.040717834331351684, 0.28143209023140137, 0.6950268037217429, 0.2082437723698606, 0.01532758730641106, 0.08139477397197598, 0.040007752265741575, 0.28405504108676516, 0.16803255951611462, 0.508098453774918, 0.9058428558278353, 0.0368478449828272, 0.029171210611404867, 0.0276358837371204, 0.8615845092416688, 0.06580120356976946, 0.026731738950218843, 0.0472946150657718, 0.7993363769790262, 0.11218756168126684, 0.0631055034457126, 0.025242201378285038, 0.2278623110049001, 0.632345169295895, 0.03924901050802107, 0.10139327714572109, 0.04433418653622121, 0.8790399054595585, 0.030575301059462903, 0.0473917166421675, 0.8300656650767858, 0.05204173448757278, 0.08847094862887372, 0.028622953968165027, 0.040674283817884974, 0.8622948169391614, 0.040674283817884974, 0.05694399734503896, 0.365069797735032, 0.11368955638807225, 0.16042859623650194, 0.36064853720882917, 0.8686103079676655, 0.06434150429390115, 0.02757493041167192, 0.036766573882229224, 0.11046720481447453, 0.034521001504523294, 0.8361753697762309, 0.019178334169179606, 0.029910874823756154, 0.03682903634761812, 0.9123834197940313, 0.021161435249460136, 0.09728036250263059, 0.22930371161334354, 0.5767335776941671, 0.09380606384182236, 0.8566850994555618, 0.08903749629172975, 0.024064188186953984, 0.031283444643040184, 0.07238824401809577, 0.38422969849387073, 0.4763422596831097, 0.06706267838188709, 0.05423593123159659, 0.7447755556624603, 0.06973191158348133, 0.1317158329910203, 0.1566208011877975, 0.2631229459954998, 0.5450403881335353, 0.03445657626131545, 0.08956172623407917, 0.7911285817343661, 0.0696591204042838, 0.04975651457448843, 0.2449417783044094, 0.27993346091932503, 0.10108708310975627, 0.3732446145591001, 0.05281232865425509, 0.4238189374503971, 0.4700297250228703, 0.05281232865425509, 0.05450081339370485, 0.2779541483078947, 0.6213092726882352, 0.04905073205433436, 0.12267495704788352, 0.3031680290978433, 0.4147821293627209, 0.1593768909187667, 0.03123490674939048, 0.03423003479385258, 0.9220715622594039, 0.012408387612771559, 0.8346084261438756, 0.06027727522150213, 0.04173042130719378, 0.06027727522150213, 0.045794468049008046, 0.7209357684286695, 0.11775720355459211, 0.11644879018176331, 0.033824688811117005, 0.08939382042938067, 0.8649456138842778, 0.01208024600397036, 0.21624387867729772, 0.34801749224627604, 0.016894053021663885, 0.4155937043329316, 0.14011434040736287, 0.21017151061104428, 0.26406164153695305, 0.39339795575913417, 0.13198134818145127, 0.7789487412277809, 0.056933130588077016, 0.031054434866223824, 0.1481139970425168, 0.1360112968950738, 0.6016770930443095, 0.11411117281874836, 0.8447292107045199, 0.048501198700737984, 0.08083533116789664, 0.024250599350368992, 0.036885705864241926, 0.8628047719548764, 0.07056395904463672, 0.028867074154624115, 0.19087770027228207, 0.15971399410537887, 0.28047335550212876, 0.3700690107319754, 0.7768214141736081, 0.07402761365466229, 0.05809762084289952, 0.09089466486711698, 0.05453470983233228, 0.7367987392240637, 0.012763442726716064, 0.19493257982620898, 0.7802692797702152, 0.17588520829918616, 0.017706564593877802, 0.027150065710612632, 0.44047120601551015, 0.04528208659972534, 0.03156024217556615, 0.4823228315091957, 0.8469481951782408, 0.11098484713766911, 0.015348968221167004, 0.02636874027738947, 0.23713112361075483, 0.3683678141586917, 0.32311378293526516, 0.07059628870854534, 0.24190389122591063, 0.30665140114511347, 0.05305698729490233, 0.3983770401973175, 0.19032716849410197, 0.6774057458699592, 0.02384609535656962, 0.10819061782147327, 0.14935184622188252, 0.1910314312140358, 0.6425602686290295, 0.01736649374673053, 0.14287789010832685, 0.278032651021609, 0.5483421728481733, 0.03089251678017878, 0.08828884207828608, 0.8021671937398565, 0.042883151866596095, 0.0655859969724411, 0.058627387976097144, 0.3177226187091716, 0.5427761402948348, 0.08132186074103798, 0.08272688099409653, 0.19854451438583168, 0.6562999225531658, 0.06066637939567079, 0.8417625805828117, 0.06685478979358071, 0.05166051938594873, 0.03950510305984315, 0.3053951268803576, 0.09209079856959236, 0.4958735307593435, 0.10625861373414502, 0.8352147263559347, 0.032726781114354994, 0.10431661480200655, 0.027272317595295827, 0.19595269065150295, 0.25410125332450995, 0.3775673795480179, 0.17205602105985626, 0.3523022615355083, 0.17498456698783527, 0.1353213984705926, 0.33830349617648153, 0.43968385397505055, 0.15702994784823232, 0.01884359374178788, 0.3768718748357576, 0.12687338016251132, 0.1638781160432438, 0.6026485557719288, 0.10572781680209277, 0.05807850422755427, 0.12544956913151722, 0.6969420507306513, 0.11848014862421072, 0.1225320712961001, 0.3801636058161054, 0.03456032780146413, 0.46185165334683886, 0.11964967679198689, 0.33033715114309425, 0.11964967679198689, 0.43177926842325703, 0.6220660260025644, 0.22204763227631646, 0.10395488402449272, 0.05156162247614839, 0.8424078946432675, 0.09385522739232056, 0.03433727831426362, 0.0274698226514109, 0.09888830676613322, 0.41752840634589583, 0.06592553784408882, 0.41752840634589583, 0.38768368112836404, 0.23483348426771872, 0.1868941043432436, 0.1903679724537128, 0.19626911030778918, 0.03340199898377943, 0.34748436152117823, 0.4228330569031923, 0.5489604667522298, 0.20722348744951719, 0.13742189167704824, 0.10688369352659308, 0.621621751834022, 0.17642960460003274, 0.07629388307028442, 0.12571151187717322, 0.8744153626852066, 0.0786150016519136, 0.031304776106899725, 0.015534700925228434, 0.09859341246920568, 0.7914119865771375, 0.042634989175872724, 0.06928185741079318, 0.233409202963947, 0.47618884838265096, 0.1371492032014433, 0.15333451289602357, 0.42417248910476546, 0.07576821561108024, 0.39244050137021047, 0.1081477949320547, 0.4204156687793006, 0.17849544558086683, 0.10600998544650467, 0.2953782500475258, 0.8690261425526052, 0.04299069256443984, 0.04913222007364553, 0.03684916505523415, 0.1014771919860209, 0.25792119629780313, 0.06765146132401394, 0.5750374212541185, 0.2711368859853327, 0.29758926510585293, 0.03306547390065033, 0.3967856868078039, 0.15150698306292007, 0.3390870573312973, 0.09379003713418861, 0.41844785798330303, 0.2859044633819402, 0.5812343486336147, 0.07728845933182119, 0.05529580830244118, 0.1493749751166847, 0.7548771063932459, 0.03067521810431918, 0.06668525674851995, 0.09273224703393709, 0.8046765952299703, 0.03888771649810265, 0.06580998176601988, 0.064307045043997, 0.5222175554434928, 0.07761195091516879, 0.3359488732470877, 0.8388996027283044, 0.10127945089886135, 0.03630772768072388, 0.022931196429930873, 0.03187239950684046, 0.9012806304989887, 0.02213361076863921, 0.045152565968023986, 0.7899277065055778, 0.09298107378659405, 0.06171310207074826, 0.05595321254414509, 0.8409814854469442, 0.07791109129481227, 0.04353855101768921, 0.036664042962264595, 0.13837321679020617, 0.12228330786111244, 0.3861578142982498, 0.3518326752495165, 0.1803637878601839, 0.41981226484697975, 0.012438881921391993, 0.38871506004349976, 0.08598431675899683, 0.36274633632701786, 0.511875385705903, 0.04030514848077976, 0.10214195026952053, 0.785216242696939, 0.03511129540514768, 0.07660646270214039, 0.7577579468178588, 0.1434745060594824, 0.06270367301858859, 0.035071545925651246, 0.10775639600683047, 0.20767596321316417, 0.6622120336419763, 0.021551279201366094, 0.8944921309847302, 0.04300442937426587, 0.0344035434994127, 0.03010310056198611, 0.8356520104223071, 0.07354752140287377, 0.03550569998759423, 0.054526610695234, 0.10608046131278397, 0.7009911565128562, 0.10034638232290374, 0.09317878358555348, 0.06924054569879946, 0.6231649112891952, 0.0703224292253432, 0.2369324923130794, 0.7344995949828131, 0.056364477312829786, 0.05812586722885572, 0.1508924028062214, 0.8462293540426142, 0.04274926134238404, 0.04944492878155263, 0.06129110963546627, 0.1396675887808611, 0.24352297531021938, 0.5729952360240457, 0.04297464270180342, 0.04230447401749181, 0.8233704109700721, 0.09792702318863845, 0.03682056071892806, 0.08993128527883047, 0.7812780408598398, 0.07306916928904976, 0.050586347969342145, 0.2193749167602342, 0.1861362930086836, 0.057613614502687774, 0.5362497965250169, 0.13536357530299106, 0.11042817985244009, 0.7017532719655064, 0.049870790901101976, 0.2095836221778699, 0.10161630166199753, 0.6414529042413594, 0.050808150830998766, 0.08325298683743147, 0.3163613499822396, 0.5291189830112312, 0.07215258859244061, 0.06885055208421322, 0.8032564409824874, 0.041310331250527924, 0.08721069930667007, 0.2233391175127774, 0.1430153998108136, 0.5289610677934201, 0.10579221355868404, 0.42949282050400067, 0.4336291879566877, 0.03860609622507871, 0.09858342428904028, 0.8494320390924569, 0.1264004810162076, 0.015084831067777863, 0.008842832005249091, 0.8138956882309535, 0.04185749253759189, 0.07557602819287425, 0.06743707131056471, 0.04646397090089458, 0.7430633485933761, 0.011525946269989353, 0.19846238733637916, 0.21198841624022935, 0.5744886080110215, 0.03391814659843669, 0.18019015380419495, 0.14341877151790228, 0.782284208279467, 0.02824915196564742, 0.04780625717263409, 0.04629699419147402, 0.7470651335442398, 0.11363807665179985, 0.09469839720983321, 0.062393436075194125, 0.8404762859540856, 0.02385631379345658, 0.07340404244140486, 0.3219414574462837, 0.19700895157160644, 0.07688154207672447, 0.40362809590280346, 0.12415361230793945, 0.7787817499316202, 0.018811153379990824, 0.0752446135199633, 0.8398547843005808, 0.022465251431908542, 0.02678549209189095, 0.11059816089554973, 0.156430780072301, 0.7472807965237308, 0.04384047339605888, 0.051811468558978675, 0.8407779096911531, 0.06777512561780537, 0.045794003795814435, 0.045794003795814435, 0.0969410993073373, 0.20465343187104543, 0.6355027621258779, 0.06462739953822487, 0.32700183407587763, 0.10308408548112216, 0.4812866242661664, 0.08874788816255551, 0.3826864776098312, 0.11737033720507709, 0.43200174534305685, 0.06805506947185141, 0.7956407661362994, 0.06035387865233724, 0.052257626637999315, 0.09200286379929458, 0.329278893066376, 0.09805193704643195, 0.4500144871907138, 0.12219905587129952, 0.054589214223124405, 0.8120145615689756, 0.09553112489046771, 0.040941910667343304, 0.11555717807969396, 0.20392443190534226, 0.5505959661444242, 0.12915214020671678, 0.11621276819945188, 0.24253099450320392, 0.5760111119451093, 0.06568547767795106, 0.45048955571361976, 0.1207007881342399, 0.20148478019258942, 0.22714557766994753, 0.16058019881894833, 0.1363416782425033, 0.5362772677538463, 0.16663982896305957, 0.5993825110537322, 0.11407962237662479, 0.11482281209894808, 0.17167682585667965, 0.8350176531971965, 0.05734026803070877, 0.027475545098047952, 0.07884286854222455, 0.24478577257788706, 0.21681025571184281, 0.1538653427632433, 0.3846633569081082, 0.1505360537616061, 0.26013686483365267, 0.5427220885615799, 0.046217209488212396, 0.5235223978867563, 0.11738392459712511, 0.141653174830286, 0.21743267045627815, 0.057200946952338905, 0.7769795294359367, 0.10010165716659308, 0.06673443811106206, 0.0881201458262729, 0.8182584969582484, 0.06504106001462999, 0.025177184521792257, 0.14446803564123134, 0.7603580823222702, 0.02142827322908216, 0.07327086975105514, 0.17624766793918806, 0.7416362264767814, 0.013960211321915886, 0.06980105660957943, 0.9012125450975971, 0.03769330036529874, 0.034266636695726126, 0.023986645687008288, 0.10085194464926663, 0.806815557194133, 0.04322226199254284, 0.05042597232463331, 0.03982250689708594, 0.7876006919645886, 0.03097306091995573, 0.14159113563408332, 0.8000834301225922, 0.048225798620316014, 0.060427506704974286, 0.09122229377577849, 0.44126322416132413, 0.2577955723245262, 0.08844081678286667, 0.2126343041800837, 0.8759525236621616, 0.08453751255055769, 0.016188034318191897, 0.023382716237388298, 0.2064545240409769, 0.4304051941871213, 0.01749614610516753, 0.3452572831419726, 0.09019465349896257, 0.26527839264400754, 0.5915708155961368, 0.050402894602361435, 0.08747310389119119, 0.30155201604594856, 0.19105967428865445, 0.4189501291630736, 0.21858965181389825, 0.18822997795085683, 0.13358256499738227, 0.4553951079456214, 0.45984741389386086, 0.11652596032344434, 0.3268983316456358, 0.09619257127371579, 0.18891851924016684, 0.602272239337652, 0.02871561492450536, 0.17909475623967816, 0.07660086532207419, 0.6794163706827451, 0.16541346279694283, 0.07882118025894591, 0.071197013994801, 0.5295277915863325, 0.06674720062012594, 0.3315110964132922, 0.058889670137123366, 0.7682836965581633, 0.09875344684532995, 0.07338558894010758, 0.7987934612488045, 0.050606790712657175, 0.10518274148120903, 0.04564534064278883, 0.05941793755761446, 0.7778348189360438, 0.07562282961878204, 0.09182772167994961, 0.18282497064572856, 0.2481987480281406, 0.4332397789241204, 0.1362877053904522, 0.07941755642921969, 0.6788310180497588, 0.11628999334278597, 0.1257444643462645, 0.0718733484918643, 0.7985927610207145, 0.09583113132248575, 0.03593667424593215, 0.04998868909716469, 0.8476342933867056, 0.06737605921791762, 0.03477474024150587, 0.2020912808784633, 0.3520299731431296, 0.07496934613233315, 0.37158719387330347, 0.16337115551989156, 0.1944894708570138, 0.5834684125710413, 0.05834684125710413, 0.20750787446089525, 0.24353354711035624, 0.5043594170924538, 0.04611286099131006, 0.28136259561009763, 0.2630677183170644, 0.4144735993628568, 0.04132118836874752, 0.8443127138245861, 0.091680420945599, 0.04264205625376698, 0.02132102812688349, 0.9435072356673726, 0.01697120453072085, 0.015595160920121863, 0.023851422583715788, 0.047323272978413176, 0.10721261279290216, 0.7053039215652765, 0.14009827706603675, 0.150185921006909, 0.3261179999007167, 0.11156668417656097, 0.41193852619037896, 0.47929880034918215, 0.1468691546374759, 0.11054667553358402, 0.26294316394773914, 0.05835998643526944, 0.849721402497523, 0.028012793488929332, 0.063028785350091, 0.6555341259258047, 0.20197814332347339, 0.06391713396312448, 0.07823457197086436, 0.08393848507816389, 0.5575913651620886, 0.1978550005413863, 0.1608820963998141, 0.19645596836896734, 0.16607617944593114, 0.3139244855380406, 0.3240510818457193, 0.1999031575820148, 0.045326878754061495, 0.7345278813478684, 0.020920097886489922, 0.16555295374076096, 0.5037447853123543, 0.14558353130510496, 0.18552237617641695, 0.7012169353971264, 0.09651341498157769, 0.15971689027924804, 0.04270505087680429, 0.1559440408995353, 0.2463387222345202, 0.1792034910676016, 0.41867010302519314, 0.1009749359845612, 0.17003250714641627, 0.622678771904794, 0.10619777750100401, 0.2477974809168943, 0.17412795956322302, 0.5458241809385644, 0.030137531462865522, 0.2340077715669801, 0.6558116959461165, 0.040312263169101616, 0.06980904109771256], \"Term\": [\"_you_\", \"_you_\", \"_you_\", \"_you_\", \"advanced\", \"advanced\", \"advanced\", \"advanced\", \"affectionate\", \"affectionate\", \"affectionate\", \"affectionate\", \"afore\", \"afore\", \"afore\", \"afore\", \"ain\", \"ain\", \"ain\", \"ain\", \"amiable\", \"amiable\", \"amiable\", \"amiable\", \"army\", \"army\", \"army\", \"army\", \"arrows\", \"arrows\", \"arrows\", \"arrows\", \"assailants\", \"assailants\", \"assailants\", \"assailants\", \"assuredly\", \"assuredly\", \"assuredly\", \"assuredly\", \"attack\", \"attack\", \"attack\", \"attack\", \"aunt\", \"aunt\", \"aunt\", \"aunt\", \"awfully\", \"awfully\", \"awfully\", \"awfully\", \"ay\", \"ay\", \"ay\", \"ay\", \"baby\", \"baby\", \"baby\", \"baby\", \"band\", \"band\", \"band\", \"band\", \"beneath\", \"beneath\", \"beneath\", \"beneath\", \"berth\", \"berth\", \"berth\", \"berth\", \"birds\", \"birds\", \"birds\", \"birds\", \"boats\", \"boats\", \"boats\", \"boats\", \"bottle\", \"bottle\", \"bottle\", \"bottle\", \"british\", \"british\", \"british\", \"british\", \"cabin\", \"cabin\", \"cabin\", \"cabin\", \"camp\", \"camp\", \"camp\", \"camp\", \"captured\", \"captured\", \"captured\", \"captured\", \"card\", \"card\", \"card\", \"card\", \"castle\", \"castle\", \"castle\", \"castle\", \"charming\", \"charming\", \"charming\", \"charming\", \"cheese\", \"cheese\", \"cheese\", \"cheese\", \"christmas\", \"christmas\", \"christmas\", \"christmas\", \"church\", \"church\", \"church\", \"church\", \"city\", \"city\", \"city\", \"city\", \"coal\", \"coal\", \"coal\", \"coal\", \"column\", \"column\", \"column\", \"column\", \"council\", \"council\", \"council\", \"council\", \"count\", \"count\", \"count\", \"count\", \"cousin\", \"cousin\", \"cousin\", \"cousin\", \"darling\", \"darling\", \"darling\", \"darling\", \"daybreak\", \"daybreak\", \"daybreak\", \"daybreak\", \"dearest\", \"dearest\", \"dearest\", \"dearest\", \"deck\", \"deck\", \"deck\", \"deck\", \"defended\", \"defended\", \"defended\", \"defended\", \"den\", \"den\", \"den\", \"den\", \"dick\", \"dick\", \"dick\", \"dick\", \"dish\", \"dish\", \"dish\", \"dish\", \"division\", \"division\", \"division\", \"division\", \"doctor\", \"doctor\", \"doctor\", \"doctor\", \"dr\", \"dr\", \"dr\", \"dr\", \"dread\", \"dread\", \"dread\", \"dread\", \"dreadfully\", \"dreadfully\", \"dreadfully\", \"dreadfully\", \"drunk\", \"drunk\", \"drunk\", \"drunk\", \"eh\", \"eh\", \"eh\", \"eh\", \"ejaculated\", \"ejaculated\", \"ejaculated\", \"ejaculated\", \"em\", \"em\", \"em\", \"em\", \"er\", \"er\", \"er\", \"er\", \"erected\", \"erected\", \"erected\", \"erected\", \"everybody\", \"everybody\", \"everybody\", \"everybody\", \"excitedly\", \"excitedly\", \"excitedly\", \"excitedly\", \"female\", \"female\", \"female\", \"female\", \"fence\", \"fence\", \"fence\", \"fence\", \"fifth\", \"fifth\", \"fifth\", \"fifth\", \"fish\", \"fish\", \"fish\", \"fish\", \"flank\", \"flank\", \"flank\", \"flank\", \"flower\", \"flower\", \"flower\", \"flower\", \"fore\", \"fore\", \"fore\", \"fore\", \"fort\", \"fort\", \"fort\", \"fort\", \"foundation\", \"foundation\", \"foundation\", \"foundation\", \"france\", \"france\", \"france\", \"france\", \"frank\", \"frank\", \"frank\", \"frank\", \"french\", \"french\", \"french\", \"french\", \"garden\", \"garden\", \"garden\", \"garden\", \"george\", \"george\", \"george\", \"george\", \"girls\", \"girls\", \"girls\", \"girls\", \"glided\", \"glided\", \"glided\", \"glided\", \"glow\", \"glow\", \"glow\", \"glow\", \"grace\", \"grace\", \"grace\", \"grace\", \"growled\", \"growled\", \"growled\", \"growled\", \"growth\", \"growth\", \"growth\", \"growth\", \"guards\", \"guards\", \"guards\", \"guards\", \"gun\", \"gun\", \"gun\", \"gun\", \"guns\", \"guns\", \"guns\", \"guns\", \"ha\", \"ha\", \"ha\", \"ha\", \"headed\", \"headed\", \"headed\", \"headed\", \"hired\", \"hired\", \"hired\", \"hired\", \"hoarse\", \"hoarse\", \"hoarse\", \"hoarse\", \"hook\", \"hook\", \"hook\", \"hook\", \"hotel\", \"hotel\", \"hotel\", \"hotel\", \"illustration\", \"illustration\", \"illustration\", \"illustration\", \"indian\", \"indian\", \"indian\", \"indian\", \"inhabitants\", \"inhabitants\", \"inhabitants\", \"inhabitants\", \"interposed\", \"interposed\", \"interposed\", \"interposed\", \"island\", \"island\", \"island\", \"island\", \"jack\", \"jack\", \"jack\", \"jack\", \"james\", \"james\", \"james\", \"james\", \"john\", \"john\", \"john\", \"john\", \"king\", \"king\", \"king\", \"king\", \"kiss\", \"kiss\", \"kiss\", \"kiss\", \"ladies\", \"ladies\", \"ladies\", \"ladies\", \"lads\", \"lads\", \"lads\", \"lads\", \"lake\", \"lake\", \"lake\", \"lake\", \"leaders\", \"leaders\", \"leaders\", \"leaders\", \"lee\", \"lee\", \"lee\", \"lee\", \"liable\", \"liable\", \"liable\", \"liable\", \"liberal\", \"liberal\", \"liberal\", \"liberal\", \"london\", \"london\", \"london\", \"london\", \"loved\", \"loved\", \"loved\", \"loved\", \"loving\", \"loving\", \"loving\", \"loving\", \"ma\", \"ma\", \"ma\", \"ma\", \"majesty\", \"majesty\", \"majesty\", \"majesty\", \"mamma\", \"mamma\", \"mamma\", \"mamma\", \"march\", \"march\", \"march\", \"march\", \"marched\", \"marched\", \"marched\", \"marched\", \"mate\", \"mate\", \"mate\", \"mate\", \"minister\", \"minister\", \"minister\", \"minister\", \"moments\", \"moments\", \"moments\", \"moments\", \"murmured\", \"murmured\", \"murmured\", \"murmured\", \"native\", \"native\", \"native\", \"native\", \"nay\", \"nay\", \"nay\", \"nay\", \"nightfall\", \"nightfall\", \"nightfall\", \"nightfall\", \"numbers\", \"numbers\", \"numbers\", \"numbers\", \"nurse\", \"nurse\", \"nurse\", \"nurse\", \"office\", \"office\", \"office\", \"office\", \"officer\", \"officer\", \"officer\", \"officer\", \"officers\", \"officers\", \"officers\", \"officers\", \"panting\", \"panting\", \"panting\", \"panting\", \"papa\", \"papa\", \"papa\", \"papa\", \"parcel\", \"parcel\", \"parcel\", \"parcel\", \"passengers\", \"passengers\", \"passengers\", \"passengers\", \"patch\", \"patch\", \"patch\", \"patch\", \"patches\", \"patches\", \"patches\", \"patches\", \"penny\", \"penny\", \"penny\", \"penny\", \"perplexed\", \"perplexed\", \"perplexed\", \"perplexed\", \"pole\", \"pole\", \"pole\", \"pole\", \"presently\", \"presently\", \"presently\", \"presently\", \"prince\", \"prince\", \"prince\", \"prince\", \"prisoners\", \"prisoners\", \"prisoners\", \"prisoners\", \"project\", \"project\", \"project\", \"project\", \"public\", \"public\", \"public\", \"public\", \"purse\", \"purse\", \"purse\", \"purse\", \"queer\", \"queer\", \"queer\", \"queer\", \"reader\", \"reader\", \"reader\", \"reader\", \"reckon\", \"reckon\", \"reckon\", \"reckon\", \"referred\", \"referred\", \"referred\", \"referred\", \"regiment\", \"regiment\", \"regiment\", \"regiment\", \"remarked\", \"remarked\", \"remarked\", \"remarked\", \"resistance\", \"resistance\", \"resistance\", \"resistance\", \"roared\", \"roared\", \"roared\", \"roared\", \"rock\", \"rock\", \"rock\", \"rock\", \"rocks\", \"rocks\", \"rocks\", \"rocks\", \"rode\", \"rode\", \"rode\", \"rode\", \"rope\", \"rope\", \"rope\", \"rope\", \"rosy\", \"rosy\", \"rosy\", \"rosy\", \"rub\", \"rub\", \"rub\", \"rub\", \"rubbing\", \"rubbing\", \"rubbing\", \"rubbing\", \"sail\", \"sail\", \"sail\", \"sail\", \"sand\", \"sand\", \"sand\", \"sand\", \"ship\", \"ship\", \"ship\", \"ship\", \"ships\", \"ships\", \"ships\", \"ships\", \"shirt\", \"shirt\", \"shirt\", \"shirt\", \"shock\", \"shock\", \"shock\", \"shock\", \"shore\", \"shore\", \"shore\", \"shore\", \"shy\", \"shy\", \"shy\", \"shy\", \"silk\", \"silk\", \"silk\", \"silk\", \"sister\", \"sister\", \"sister\", \"sister\", \"sisters\", \"sisters\", \"sisters\", \"sisters\", \"slain\", \"slain\", \"slain\", \"slain\", \"slender\", \"slender\", \"slender\", \"slender\", \"sofa\", \"sofa\", \"sofa\", \"sofa\", \"soldiers\", \"soldiers\", \"soldiers\", \"soldiers\", \"south\", \"south\", \"south\", \"south\", \"spanish\", \"spanish\", \"spanish\", \"spanish\", \"st\", \"st\", \"st\", \"st\", \"staring\", \"staring\", \"staring\", \"staring\", \"steam\", \"steam\", \"steam\", \"steam\", \"stomach\", \"stomach\", \"stomach\", \"stomach\", \"stream\", \"stream\", \"stream\", \"stream\", \"street\", \"street\", \"street\", \"street\", \"study\", \"study\", \"study\", \"study\", \"sunday\", \"sunday\", \"sunday\", \"sunday\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"sword\", \"sword\", \"sword\", \"sword\", \"sympathetic\", \"sympathetic\", \"sympathetic\", \"sympathetic\", \"tail\", \"tail\", \"tail\", \"tail\", \"tea\", \"tea\", \"tea\", \"tea\", \"tenderly\", \"tenderly\", \"tenderly\", \"tenderly\", \"term\", \"term\", \"term\", \"term\", \"thou\", \"thou\", \"thou\", \"thou\", \"thoughtfully\", \"thoughtfully\", \"thoughtfully\", \"thoughtfully\", \"thrust\", \"thrust\", \"thrust\", \"thrust\", \"tom\", \"tom\", \"tom\", \"tom\", \"troop\", \"troop\", \"troop\", \"troop\", \"troops\", \"troops\", \"troops\", \"troops\", \"uncle\", \"uncle\", \"uncle\", \"uncle\", \"union\", \"union\", \"union\", \"union\", \"vessel\", \"vessel\", \"vessel\", \"vessel\", \"vi\", \"vi\", \"vi\", \"vi\", \"village\", \"village\", \"village\", \"village\", \"wasn\", \"wasn\", \"wasn\", \"wasn\", \"wheel\", \"wheel\", \"wheel\", \"wheel\", \"wolf\", \"wolf\", \"wolf\", \"wolf\", \"works\", \"works\", \"works\", \"works\", \"wounded\", \"wounded\", \"wounded\", \"wounded\", \"ye\", \"ye\", \"ye\", \"ye\", \"yer\", \"yer\", \"yer\", \"yer\", \"yonder\", \"yonder\", \"yonder\", \"yonder\", \"youth\", \"youth\", \"youth\", \"youth\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 1, 2, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el108401402717142992328554899208\", ldavis_el108401402717142992328554899208_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el108401402717142992328554899208\", ldavis_el108401402717142992328554899208_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el108401402717142992328554899208\", ldavis_el108401402717142992328554899208_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "2      0.067144 -0.057703       1        1  35.723702\n",
       "0      0.012048  0.063136       2        1  35.454139\n",
       "1     -0.099979 -0.026718       3        1  17.201155\n",
       "3      0.020787  0.021285       4        1  11.621004, topic_info=         Term         Freq        Total Category  logprob  loglift\n",
       "815      dick  4914.000000  4914.000000  Default  30.0000  30.0000\n",
       "1564     jack  3862.000000  3862.000000  Default  29.0000  29.0000\n",
       "2989    uncle  3740.000000  3740.000000  Default  28.0000  28.0000\n",
       "989        er  2337.000000  2337.000000  Default  27.0000  27.0000\n",
       "870    doctor  5069.000000  5069.000000  Default  26.0000  26.0000\n",
       "...       ...          ...          ...      ...      ...      ...\n",
       "1572     john   290.175681  2306.869082   Topic4  -5.9127   0.0792\n",
       "2747   street   237.391109  1323.321827   Topic4  -6.1135   0.4342\n",
       "1915  officer   257.116585  1703.200395   Topic4  -6.0337   0.2616\n",
       "870    doctor   339.829496  5069.883998   Topic4  -5.7548  -0.5503\n",
       "1255    girls   245.323294  2264.521683   Topic4  -6.0807  -0.0702\n",
       "\n",
       "[258 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "5         1  0.049988     _you_\n",
       "5         2  0.864494     _you_\n",
       "5         3  0.020583     _you_\n",
       "5         4  0.064690     _you_\n",
       "56        1  0.763321  advanced\n",
       "...     ...       ...       ...\n",
       "3193      4  0.030138    yonder\n",
       "3196      1  0.234008     youth\n",
       "3196      2  0.655812     youth\n",
       "3196      3  0.040312     youth\n",
       "3196      4  0.069809     youth\n",
       "\n",
       "[824 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 1, 2, 4])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.sklearn.prepare(lda, dtm, tf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some hints to help you interpret the visualisation:\n",
    "\n",
    "* On the **left-hand side** is a scatterplot of some bubbles:\n",
    " * Each **bubble** represents a topic.\n",
    " * The **size of a bubble** represents how _prevalent_ or popular the topic is overall.\n",
    " * The **distance** from one bubble to another represents how similar the topics are to each other. If they overlap then the topics share significant similarity.\n",
    " \n",
    "* On the **right-hand side** is a histogram of terms (tokens):\n",
    " * Select a bubble and it shows the top-30 **most relevant terms** for that topic.\n",
    " * The **red bar** represents how frequent a term is in the topic.\n",
    " * The **blue bar** represents how frequent the term is overall in all topics. So a long red bar with only a short blue bar indicates a term that is highly specific to that particular topic. Conversely, a red bar with a long blue bar means the term is also present in many other topics.\n",
    " * By mousing over a particular term, the size of the bubbles changes to show the relative frequency of that term in the various topics.\n",
    " * By adjusting the slide, it adjusts the **_relevance_ value (λ)**, which is the weight given to whether a term appears exclusively in a particular topic or is spread over topics more evenly. If λ = 1 terms are ranked according to their probabilities in the particular topic only; if λ = 0 terms are ranked higher if they are unusual terms that occur almost exclusively in that topic. Typically, the optimal value is around 0.6, but it is interesting to adjust it and observe any differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the topic model <a id='eval'></a>\n",
    "\n",
    "#### TO DO: Add code here\n",
    "\n",
    "Use tmtoolkit: https://tmtoolkit.readthedocs.io/en/latest/topic_modeling.html\n",
    "\n",
    "Consider grid search too: https://www.machinelearningplus.com/nlp/topic-modeling-python-sklearn-examples/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Resources and alternatives <a id='resources'></a>\n",
    "\n",
    "In addition to LDA in `scikit-learn`, there are a few other common tools for topic modeling in Python:\n",
    "- [Here's a detailed example of using LDA in scikit-learn](https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-plot-topics-extraction-with-nmf-lda-py), including several alternatives (like NMF) we won't explore.\n",
    "- The other major topic modeling package is [Gensim](https://radimrehurek.com/gensim/) (example implementation [here](https://github.com/bhargavvader/personal/blob/master/notebooks/text_analysis_tutorial/topic_modelling.ipynb) and [here](https://github.com/susanli2016/NLP-with-Python/blob/master/LDA_news_headlines.ipynb)). \n",
    "- Another option is [textacy](https://textacy.readthedocs.io/en/latest/), which is built on the powerful spaCy library for text manipulation ([example implementation](https://github.com/repmax/topic-model/blob/master/topic-modelling.ipynb)).\n",
    "\n",
    "Another well-known tool for topic modeling is called [MALLET](http://mallet.cs.umass.edu/topics.php), which is a program (written in Java) that you download to your computer. You have to type commands to use MALLET, but it has otherwise done a great deal for you. \n",
    "- [Getting Started with Topic Modeling and MALLET](https://programminghistorian.org/en/lessons/topic-modeling-and-mallet) from Programming Historian gives a step-by-step tutorial on MALLET.\n",
    "- There is a graphical interface for MALLET called [Topic Modeling Tool](https://github.com/senderle/topic-modeling-tool) that is a bit easier to use. The [Quickstart Guide](https://senderle.github.io/topic-modeling-tool/documentation/2017/01/06/quickstart.html) will get you up and running.\n",
    "\n",
    "If you are looking to use R rather than Python, then `tidytext` is a popular NLP library that will help you work with the `topicmodels` package. \n",
    "- The book _Text Mining with R_ devotes [chapter 6](https://www.tidytextmining.com/topicmodeling.html) to tidytext.\n",
    "\n",
    "Finally, if coding isn't your thing, you can explore the topics of a few documents in a casual way with the online digital text environment [Voyant Tools](https://voyant-tools.org/), which allows you to upload or copy-and-paste texts and explore a corpus with a number of graphical tools, including topics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
